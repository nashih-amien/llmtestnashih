{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3cd9d56",
   "metadata": {},
   "source": [
    "# Fine-Tune a Generative AI Model for Dialogue Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c4ed2c",
   "metadata": {},
   "source": [
    "Di minggu ini memungkinkan Anda untuk mencoba fine-tuning menggunakan PEFT dengan LoRA sendiri dengan meningkatkan kemampuan ringkasan model Flan-T5.Di Lab 2, Anda akan berlatih dengan ***full fine-tuning*** dan ***Fine-Tuning Parameter-Efficient* (PEFT)**, juga disebut **PEFT dengan instruksi prompt**. Anda akan ***fine-tune* model Flan-T5 lebih lanjut dengan prompt khusus Anda sendiri untuk tugas ringkasan Anda yang spesifik**. Mari langsung beralih ke buku catatan. Di Lab 2, kita akan benar-benar *fine-tune* model. Di Lab 1, kita melakukan *zero-shot inference*, pembelajaran dalam konteks. Sekarang kita benar-benar akan **memodifikasi bobot model bahasa kita, khusus untuk tugas ringkasan kita dan spesifik untuk dataset kita**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d681ee7",
   "metadata": {},
   "source": [
    "Mari kita lakukan instalasi pip ini. Sementara instalasi pip sedang berlangsung, biarkan saya menjelaskan tentang torch dan torchdata sama seperti Lab 1 di mana kita akan menggunakan PyTorch, kemudian kita memasang **library torchdata untuk membantu dengan pemuatan data PyTorch**. Ada juga **library bernama evaluates, dan ini yang akan kita gunakan dengan skor rouge untuk menghitung rouge**. Anda mempelajari tentang **rouge dalam pelajaran sebagai cara untuk mengukur seberapa baik ringkasan menggambarkan apa yang ada dalam percakapan asli atau teks asli**. Sekarang, dua library ini, LoRA dan PEFT, Anda mendengarnya sedikit dalam pelajaran. Ini yang akan kita gunakan untuk melakukan fine-tuning yang efisien dalam parameter (PEFT)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea0f8cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\247\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\247\\anaconda3\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\247\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\247\\anaconda3\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\247\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\247\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\247\\anaconda3\\lib\\site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\247\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\247\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torchdata in c:\\users\\247\\anaconda3\\lib\\site-packages (0.7.1)\n",
      "Requirement already satisfied: urllib3>=1.25 in c:\\users\\247\\anaconda3\\lib\\site-packages (from torchdata) (1.26.16)\n",
      "Requirement already satisfied: requests in c:\\users\\247\\anaconda3\\lib\\site-packages (from torchdata) (2.31.0)\n",
      "Requirement already satisfied: torch>=2 in c:\\users\\247\\anaconda3\\lib\\site-packages (from torchdata) (2.2.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\247\\anaconda3\\lib\\site-packages (from torch>=2->torchdata) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\247\\anaconda3\\lib\\site-packages (from torch>=2->torchdata) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\247\\anaconda3\\lib\\site-packages (from torch>=2->torchdata) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\247\\anaconda3\\lib\\site-packages (from torch>=2->torchdata) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\247\\anaconda3\\lib\\site-packages (from torch>=2->torchdata) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\247\\anaconda3\\lib\\site-packages (from torch>=2->torchdata) (2024.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\247\\anaconda3\\lib\\site-packages (from requests->torchdata) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\247\\anaconda3\\lib\\site-packages (from requests->torchdata) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\247\\anaconda3\\lib\\site-packages (from requests->torchdata) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\247\\anaconda3\\lib\\site-packages (from jinja2->torch>=2->torchdata) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\247\\anaconda3\\lib\\site-packages (from sympy->torch>=2->torchdata) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: transformers in c:\\users\\247\\anaconda3\\lib\\site-packages (4.32.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\247\\anaconda3\\lib\\site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in c:\\users\\247\\anaconda3\\lib\\site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\247\\anaconda3\\lib\\site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\247\\anaconda3\\lib\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\247\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\247\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in c:\\users\\247\\anaconda3\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\247\\anaconda3\\lib\\site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\247\\anaconda3\\lib\\site-packages (from transformers) (0.3.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\247\\anaconda3\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\247\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\247\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\247\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\247\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\247\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\247\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\247\\anaconda3\\lib\\site-packages (from requests->transformers) (2023.7.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: datasets in c:\\users\\247\\anaconda3\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\247\\anaconda3\\lib\\site-packages (from datasets) (3.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\247\\anaconda3\\lib\\site-packages (from datasets) (1.24.3)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in c:\\users\\247\\anaconda3\\lib\\site-packages (from datasets) (15.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\247\\anaconda3\\lib\\site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\247\\anaconda3\\lib\\site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in c:\\users\\247\\anaconda3\\lib\\site-packages (from datasets) (2.0.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\247\\anaconda3\\lib\\site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\247\\anaconda3\\lib\\site-packages (from datasets) (4.65.0)\n",
      "Requirement already satisfied: xxhash in c:\\users\\247\\anaconda3\\lib\\site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\247\\anaconda3\\lib\\site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in c:\\users\\247\\anaconda3\\lib\\site-packages (from datasets) (2024.2.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\247\\anaconda3\\lib\\site-packages (from datasets) (3.8.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in c:\\users\\247\\anaconda3\\lib\\site-packages (from datasets) (0.22.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\247\\anaconda3\\lib\\site-packages (from datasets) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\247\\anaconda3\\lib\\site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\247\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\247\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\247\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\247\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\247\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\247\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\247\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\247\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.19.4->datasets) (4.11.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\247\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\247\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\247\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\247\\anaconda3\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\247\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\247\\anaconda3\\lib\\site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\247\\anaconda3\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\247\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: datasets in c:\\users\\247\\anaconda3\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\247\\anaconda3\\lib\\site-packages (from datasets) (3.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\247\\anaconda3\\lib\\site-packages (from datasets) (1.24.3)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in c:\\users\\247\\anaconda3\\lib\\site-packages (from datasets) (15.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\247\\anaconda3\\lib\\site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\247\\anaconda3\\lib\\site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in c:\\users\\247\\anaconda3\\lib\\site-packages (from datasets) (2.0.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\247\\anaconda3\\lib\\site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\247\\anaconda3\\lib\\site-packages (from datasets) (4.65.0)\n",
      "Requirement already satisfied: xxhash in c:\\users\\247\\anaconda3\\lib\\site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\247\\anaconda3\\lib\\site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in c:\\users\\247\\anaconda3\\lib\\site-packages (from datasets) (2024.2.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\247\\anaconda3\\lib\\site-packages (from datasets) (3.8.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in c:\\users\\247\\anaconda3\\lib\\site-packages (from datasets) (0.22.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\247\\anaconda3\\lib\\site-packages (from datasets) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\247\\anaconda3\\lib\\site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\247\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\247\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\247\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\247\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\247\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\247\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\247\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\247\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.19.4->datasets) (4.11.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\247\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\247\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\247\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\247\\anaconda3\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\247\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\247\\anaconda3\\lib\\site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\247\\anaconda3\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\247\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: evaluate in c:\\users\\247\\anaconda3\\lib\\site-packages (0.4.1)\n",
      "Requirement already satisfied: datasets>=2.0.0 in c:\\users\\247\\anaconda3\\lib\\site-packages (from evaluate) (2.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\247\\anaconda3\\lib\\site-packages (from evaluate) (1.24.3)\n",
      "Requirement already satisfied: dill in c:\\users\\247\\anaconda3\\lib\\site-packages (from evaluate) (0.3.6)\n",
      "Requirement already satisfied: pandas in c:\\users\\247\\anaconda3\\lib\\site-packages (from evaluate) (2.0.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\247\\anaconda3\\lib\\site-packages (from evaluate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\247\\anaconda3\\lib\\site-packages (from evaluate) (4.65.0)\n",
      "Requirement already satisfied: xxhash in c:\\users\\247\\anaconda3\\lib\\site-packages (from evaluate) (2.0.2)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\247\\anaconda3\\lib\\site-packages (from evaluate) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in c:\\users\\247\\anaconda3\\lib\\site-packages (from evaluate) (2024.2.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in c:\\users\\247\\anaconda3\\lib\\site-packages (from evaluate) (0.22.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\247\\anaconda3\\lib\\site-packages (from evaluate) (23.1)\n",
      "Requirement already satisfied: responses<0.19 in c:\\users\\247\\anaconda3\\lib\\site-packages (from evaluate) (0.13.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\247\\anaconda3\\lib\\site-packages (from datasets>=2.0.0->evaluate) (3.9.0)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in c:\\users\\247\\anaconda3\\lib\\site-packages (from datasets>=2.0.0->evaluate) (15.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\247\\anaconda3\\lib\\site-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\247\\anaconda3\\lib\\site-packages (from datasets>=2.0.0->evaluate) (3.8.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\247\\anaconda3\\lib\\site-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\247\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.7.0->evaluate) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\247\\anaconda3\\lib\\site-packages (from requests>=2.19.0->evaluate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\247\\anaconda3\\lib\\site-packages (from requests>=2.19.0->evaluate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\247\\anaconda3\\lib\\site-packages (from requests>=2.19.0->evaluate) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\247\\anaconda3\\lib\\site-packages (from requests>=2.19.0->evaluate) (2023.7.22)\n",
      "Requirement already satisfied: six in c:\\users\\247\\anaconda3\\lib\\site-packages (from responses<0.19->evaluate) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\247\\anaconda3\\lib\\site-packages (from tqdm>=4.62.1->evaluate) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\247\\anaconda3\\lib\\site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\247\\anaconda3\\lib\\site-packages (from pandas->evaluate) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\247\\anaconda3\\lib\\site-packages (from pandas->evaluate) (2023.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\247\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (22.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\247\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\247\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\247\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\247\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\247\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: rouge_score in c:\\users\\247\\anaconda3\\lib\\site-packages (0.1.2)\n",
      "Requirement already satisfied: absl-py in c:\\users\\247\\anaconda3\\lib\\site-packages (from rouge_score) (2.1.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\247\\anaconda3\\lib\\site-packages (from rouge_score) (3.8.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\247\\anaconda3\\lib\\site-packages (from rouge_score) (1.24.3)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\users\\247\\anaconda3\\lib\\site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: click in c:\\users\\247\\anaconda3\\lib\\site-packages (from nltk->rouge_score) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\247\\anaconda3\\lib\\site-packages (from nltk->rouge_score) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\247\\anaconda3\\lib\\site-packages (from nltk->rouge_score) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\users\\247\\anaconda3\\lib\\site-packages (from nltk->rouge_score) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\247\\anaconda3\\lib\\site-packages (from click->nltk->rouge_score) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: loralib in c:\\users\\247\\anaconda3\\lib\\site-packages (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: peft in c:\\users\\247\\anaconda3\\lib\\site-packages (0.10.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\247\\anaconda3\\lib\\site-packages (from peft) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\247\\anaconda3\\lib\\site-packages (from peft) (23.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\247\\anaconda3\\lib\\site-packages (from peft) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\247\\anaconda3\\lib\\site-packages (from peft) (6.0)\n",
      "Requirement already satisfied: torch>=1.13.0 in c:\\users\\247\\anaconda3\\lib\\site-packages (from peft) (2.2.2)\n",
      "Requirement already satisfied: transformers in c:\\users\\247\\anaconda3\\lib\\site-packages (from peft) (4.32.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\247\\anaconda3\\lib\\site-packages (from peft) (4.65.0)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in c:\\users\\247\\anaconda3\\lib\\site-packages (from peft) (0.29.2)\n",
      "Requirement already satisfied: safetensors in c:\\users\\247\\anaconda3\\lib\\site-packages (from peft) (0.3.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in c:\\users\\247\\anaconda3\\lib\\site-packages (from peft) (0.22.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\247\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.17.0->peft) (3.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\247\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.17.0->peft) (2024.2.0)\n",
      "Requirement already satisfied: requests in c:\\users\\247\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.17.0->peft) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\247\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.17.0->peft) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\247\\anaconda3\\lib\\site-packages (from torch>=1.13.0->peft) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\247\\anaconda3\\lib\\site-packages (from torch>=1.13.0->peft) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\247\\anaconda3\\lib\\site-packages (from torch>=1.13.0->peft) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\247\\anaconda3\\lib\\site-packages (from tqdm->peft) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\247\\anaconda3\\lib\\site-packages (from transformers->peft) (2022.7.9)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\247\\anaconda3\\lib\\site-packages (from transformers->peft) (0.13.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\247\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.13.0->peft) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\247\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.17.0->peft) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\247\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\247\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.17.0->peft) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\247\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.17.0->peft) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\247\\anaconda3\\lib\\site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch\n",
    "%pip install torchdata\n",
    "%pip install transformers\n",
    "%pip install datasets\n",
    "%pip install -U datasets \n",
    "%pip install evaluate\n",
    "%pip install rouge_score\n",
    "%pip install loralib\n",
    "%pip install peft"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb263908",
   "metadata": {},
   "source": [
    "## 1. Set up Kernel, Load Required Dependencies, Dataset and LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4986b2d5",
   "metadata": {},
   "source": [
    "### 1.1 Set up Kernel and Required Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ff918f",
   "metadata": {},
   "source": [
    "Kita memiliki **AutoModelForSeq2Seq**. Ini yang akan memberi kita akses ke Flan-T5 melalui perpustakaan python transformers, tokenizer, kita menggunakan generation config di lab sebelumnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0328d584",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\247\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "C:\\Users\\247\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig, TrainingArguments, Trainer\n",
    "import torch\n",
    "import time\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076cdf56",
   "metadata": {},
   "source": [
    "Mari muat dataset seperti yang kita lakukan di lab pertama."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36492ad0",
   "metadata": {},
   "source": [
    "### 1.2 Load Dataset and LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bad3633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bcfbe6972b54f4ca58be0cb05c12da1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/4.65k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 11.3M/11.3M [00:02<00:00, 4.48MB/s]\n",
      "Downloading data: 100%|██████████| 442k/442k [00:00<00:00, 465kB/s]\n",
      "Downloading data: 100%|██████████| 1.35M/1.35M [00:01<00:00, 1.14MB/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "934005edd23e455e8f439a9bdfc4e54c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc79cad174054220a37da014a93553cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90598db332644b839046555d9c3f6116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
       "        num_rows: 12460\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
       "        num_rows: 500\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
       "        num_rows: 1500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "huggingface_dataset_name = \"knkarthick/dialogsum\"\n",
    "dataset = load_dataset(huggingface_dataset_name)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fd1bcb",
   "metadata": {},
   "source": [
    "Mari **muat model** seperti yang kita lakukan di lab pertama dan tokenizer, dan ini disebut **model asli** dan ini akan **berguna nanti saat kita membandingkan semua strategi fine-tuning dengan model asli yang tidak disesuaikan.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3b32435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0451fe13cf7c440db1f59cfaee2b39a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\247\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:148: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\247\\.cache\\huggingface\\hub\\models--google--flan-t5-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bab3d4986ef420683b6e77004fbb6bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f63807836566477f963ceb858b7c1a94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f3c0e226fbd4cf1976044b1e8ae4e83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb9affb0421740a0bdba0f91e98ad632",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ae57a5609114c6b80638cdfa7dffb76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34ecd8fde64f4d39a290a02082a11729",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name='google/flan-t5-base'\n",
    "\n",
    "original_model = AutoModelForSeq2SeqLM.from_pretrained(model_name, torch_dtype=torch.bfloat16)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317066a6",
   "metadata": {},
   "source": [
    "Berikut adalah fungsi kenyamanan yang **mencetak semua parameter yang ada dalam model dan khususnya parameter yang dapat dilatih**. Ini akan menjadi berguna ketika kita **memperkenalkan versi model PEFT yang tidak melatih semua parameter**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f526d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable model params: 247577856\n",
      "all model params: 247577856\n"
     ]
    }
   ],
   "source": [
    "def print_number_of_trainable_model_parameters(model):\n",
    "    trainable_model_params = 0\n",
    "    all_model_params = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_model_params += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_model_params += param.numel()\n",
    "    return f\"trainable model params: {trainable_model_params}\\nall model params: {all_model_params}\"\n",
    "\n",
    "print(print_number_of_trainable_model_parameters(original_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1b1da3",
   "metadata": {},
   "source": [
    "Di sini kita melihat ada **sekitar 250 juta parameter yang dilatih ketika kita melakukan *full fine-tuning***, yang merupakan bagian pertama dari lab ini di mana kita melakukan *full fine-tuning*. Bagian kedua dari lab ini akan menjadi di mana kita melakukan **fine-tuning efisien parameter (PEFT) khusus dengan LoRA**, di mana kita **hanya akan melatih jumlah yang sangat kecil**. Jadi ingatlah, ini adalah jenis kode yang agak berantakan tapi cukup berguna untuk perbandingan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04c2d9a",
   "metadata": {},
   "source": [
    "### 1.3 Test and Model with Zero Shot Inferences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b914cd",
   "metadata": {},
   "source": [
    "Sama seperti yang kita lakukan di lab pertama, kita akan menunjukkan contoh input. Kita akan menunjukkan baseline manusia. Kita akan melakukan ***zero-shot***. Ini bukan one shot, bukan few shot, kita lewati itu, itu adalah Lab 1. Di sini, kita mencoba mencapai titik di mana **satu panggilan sederhana ke model kita bisa memberikan ringkasan yang layak tanpa harus melewati one-shot dan few shot contoh**, itulah tujuannya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "654ea29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "\n",
      "Summarize the following conversation.\n",
      "\n",
      "#Person1#: Have you considered upgrading your system?\n",
      "#Person2#: Yes, but I'm not sure what exactly I would need.\n",
      "#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n",
      "#Person2#: That would be a definite bonus.\n",
      "#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n",
      "#Person2#: How can we do that?\n",
      "#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n",
      "#Person2#: No.\n",
      "#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n",
      "#Person2#: That sounds great. Thanks.\n",
      "\n",
      "Summary:\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "MODEL GENERATION - ZERO SHOT:\n",
      "#Person1#: I'm thinking of upgrading my computer.\n"
     ]
    }
   ],
   "source": [
    "index = 200\n",
    "\n",
    "dialogue = dataset['test'][index]['dialogue']\n",
    "summary = dataset['test'][index]['summary']\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Summarize the following conversation.\n",
    "\n",
    "{dialogue}\n",
    "\n",
    "Summary:\n",
    "\"\"\"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors='pt')\n",
    "output = tokenizer.decode(\n",
    "    original_model.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        max_new_tokens=200,\n",
    "    )[0],\n",
    "    skip_special_tokens = True\n",
    ")\n",
    "\n",
    "dash_line = '-'.join('' for x in range(100))\n",
    "print(dash_line)\n",
    "print(f'INPUT PROMPT:\\n{prompt}')\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')\n",
    "print(dash_line)\n",
    "print(f'MODEL GENERATION - ZERO SHOT:\\n{output}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d1148a",
   "metadata": {},
   "source": [
    "## 2. Perform Full Fine-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd39b34",
   "metadata": {},
   "source": [
    "### 2.1 Preprocess the Dialog Summary Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54467636",
   "metadata": {},
   "source": [
    "Cara pertama yang akan kita lakukan adalah kita akan **melakukan full fine-tuning**. Berikut adalah **fungsi kenyamanan yang dapat menokenisasi dan membungkus dataset kita dalam sebuah prompt**. Seperti yang kita lihat di lab pertama di mana kita memiliki prompt yang mengatakan ringkaslah percakapan berikut, dan kemudian kita sebenarnya akan memberikan dialog tersebut, dan kemudian kita akan mengakhiri prompt dengan ringkasan itu titik dua. **Fungsi ini akan memungkinkan kita memetakan semua elemen dataset kita dan mengubahnya menjadi prompt dengan instruksi**. Itulah yang akan kita lakukan di sini, yaitu **full fine-tuning dengan prompt instruksi.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "238bbd8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cdfb782a00143428bd230b37dc1932f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12460 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8abd1c9529d9446bb685779616927473",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3dafbd4c73f404c96baf46a6bb4ae5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_function(example):\n",
    "    start_prompt = 'summarize the following conversation. \\n\\n'\n",
    "    end_prompt = '\\n\\nSummary: '\n",
    "    prompt = [start_prompt + dialogue + end_prompt for dialogue in example[\"dialogue\"]]\n",
    "    example['input_ids'] = tokenizer(prompt, padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n",
    "    example['labels'] = tokenizer(example[\"summary\"], padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n",
    "    \n",
    "    return example\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_datasets = tokenized_datasets.remove_columns(['id','topic','dialogue','summary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c457843e",
   "metadata": {},
   "source": [
    "Di sini, kita hanya akan mengambil sampel hanya untuk menjaga kebutuhan sumber daya untuk lab tertentu ini, mempercepat sedikit. Mari kita lihat ukurannya."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341d09ab",
   "metadata": {},
   "source": [
    "Untuk menghemat waktu dalam lab, Anda akan **mengambil sampel acak dari dataset**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1a048d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7615edd5f2d43669c9d3c718c17f844",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/12460 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae9096402d8f4e37ae25149efa158086",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c67a727a23749249aa80375ff737c00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = tokenized_datasets.filter(lambda example, index: index % 100 == 0, with_indices=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66080779",
   "metadata": {},
   "source": [
    "Periksa bentuk dari ketiga bagian dataset ini:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56ccdc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes of the datasets:\n",
      "Training: (125, 2)\n",
      "Validation: (5, 2)\n",
      "Test: (15, 2)\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'labels'],\n",
      "        num_rows: 125\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['input_ids', 'labels'],\n",
      "        num_rows: 5\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input_ids', 'labels'],\n",
      "        num_rows: 15\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(f\"shapes of the datasets:\")\n",
    "print(f\"Training: {tokenized_datasets['train'].shape}\")\n",
    "print(f\"Validation: {tokenized_datasets['validation'].shape}\")\n",
    "print(f\"Test: {tokenized_datasets['test'].shape}\")\n",
    "\n",
    "print(tokenized_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8850a456",
   "metadata": {},
   "source": [
    "Di sini kita memiliki sekitar **125 contoh pelatihan**. Kita akan menggunakan **5 untuk validasi**. Kita akan menggunakan **15 untuk benar-benar melakukan uji coba holdout nanti saat kita membandingkan**. Kita akan **fine-tune dengan pelatihan dan kita akan memvalidasi dengan validasi**. Kemudian setelah semuanya selesai, kita akan menggunakan **15 contoh uji untuk kemudian membandingkan berbagai strategi untuk fine-tuning dengan instruksi**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab1d293",
   "metadata": {},
   "source": [
    "### 2.2 Fine-Tune the Model with Preprocessed Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddba350d",
   "metadata": {},
   "source": [
    "Di sini kita melihat **argumen pelatihan** dan kita melihat beberapa **default di sini untuk tingkat pembelajaran**. Kita **melihat beberapa nilai yang cukup rendah untuk langkah maksimum dan jumlah epoch**. Itu karena kita ingin mencoba meminimalkan jumlah komputasi yang diperlukan untuk lab ini. Jika Anda memiliki lebih banyak waktu, Anda tentu bisa mengubah nilai-nilai ini dan menaikkannya mungkin menjadi lima epoch, mungkin langkah maksimum 100. Sesaat lagi, saya akan menunjukkan bagaimana kita sebenarnya bekerja di sekitarnya. Kami telah melatih secara offline model yang jauh lebih besar dengan langkah maksimum yang lebih tinggi dan epoch pelatihan yang lebih tinggi dan sebentar lagi, kami akan benar-benar menariknya dan kemudian melanjutkan dari sana. Tetapi inilah tampilan kode. Inilah dataset pelatihan, inilah dataset evaluasi validasi, inilah tempat kita memanggil pelatihan. Sebenarnya biarkan saya hanya melakukan Shift Enter, mulailah ini. Ini akan memakan beberapa menit, bahkan dengan langkah maksimum yang rendah dan jumlah epoch yang rendah, ini masih membutuhkan beberapa menit untuk dijalankan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09248295",
   "metadata": {},
   "source": [
    "Sekarang gunakan Trainer class bawaan dari Hugging Face. Berikan dataset yang sudah diproses dengan referensi ke model asli. Parameter pelatihan lainnya ditemukan secara eksperimental dan tidak perlu menjelaskan detail tentang itu saat ini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07f72b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from accelerate import DataLoaderConfiguration, Accelerator\n",
    "\n",
    "# Menghilangkan peringatan FutureWarning\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Konfigurasi DataLoaderConfiguration\n",
    "dataloader_config = DataLoaderConfiguration(\n",
    "    dispatch_batches=None, \n",
    "    split_batches=False, \n",
    "    even_batches=True, \n",
    "    use_seedable_sampler=True\n",
    ")\n",
    "\n",
    "# Membuat objek Accelerator dengan konfigurasi DataLoaderConfiguration\n",
    "accelerator = Accelerator(dataloader_config=dataloader_config)\n",
    "\n",
    "# Sekarang Anda dapat menggunakan objek accelerator dengan benar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66f59002",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = f'./dialogue_summary_training'\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = output_dir,\n",
    "    learning_rate = 1e-5,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=1,\n",
    "    max_steps=1\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=original_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'], # training dataset \n",
    "    eval_dataset=tokenized_datasets['validation']) # evaluation dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40ada1c",
   "metadata": {},
   "source": [
    "Proses training dimulai..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7d84ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d63bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec50b4e",
   "metadata": {},
   "source": [
    "Buatlah sebuah contoh dari **AutoModelForSeq2SeqLM class** untuk instruct model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94529914",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruct_model = AutoModelForSeq2SeqLM.from_pretrained(\"./dialogue_summary_training\", torch_dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f2863d",
   "metadata": {},
   "source": [
    "### 2.3 Evaluate the Model Qualitatively (Human Evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c71490",
   "metadata": {},
   "source": [
    "Seperti halnya dengan banyak aplikasi AI, pendekatan kualitatif di mana Anda bertanya pada diri sendiri, \"apakah model saya berperilaku sesuai yang diharapkan?\" biasanya merupakan titik awal yang baik. Pada contoh di bawah ini (sama dengan yang kita mulai di notebook ini), Anda dapat melihat **bagaimana model yang fine-tuned dapat membuat ringkasan yang masuk akal dari dialog dibandingkan dengan ketidakmampuan asli untuk memahami apa yang diminta dari model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad008498",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 200\n",
    "dialogue = dataset['test'][index]['dialogue']\n",
    "human_baseline_summary = dataset['test'][index]['summary']\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Summarize the following conversation:\n",
    "\n",
    "{dialogue}\n",
    "\n",
    "Summary:\n",
    "\"\"\"\n",
    "\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "original_model_outputs = original_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200, num_beams=1))\n",
    "original_model_text_outputs = tokenizer.decode(original_model_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "\n",
    "instruct_model_outputs = instruct_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200, num_beams=1))\n",
    "instruct_model_text_outputs = tokenizer.decode(instruct_model_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(f'dialogue:\\n{dialogue}\\n')\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{human_baseline_summary}\\n')\n",
    "print(f'ORIGINAL MODEL:\\n{original_model_text_outputs}\\n')\n",
    "print(f'INSTRUCT MODEL:\\n{instruct_model_text_outputs}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dad32c1",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------\n",
    "**BASELINE HUMAN SUMMARY:**\n",
    "\n",
    "#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n",
    "\n",
    "**ORIGINAL MODEL:**\n",
    "\n",
    "#Person1#: You'd like to upgrade your computer. #Person2: You'd like to upgrade your computer.\n",
    "\n",
    "**INSTRUCT MODEL:**\n",
    "\n",
    "#Person1# suggests #Person2# upgrading #Person2#'s system, hardware, and CD-ROM drive. #Person2# thinks it's great."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23a86cd",
   "metadata": {},
   "source": [
    "### 2.4 Evaluate the Model Quantitatively (with ROUGE Metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832e91ca",
   "metadata": {},
   "source": [
    "**Metrik ROUGE membantu mengkuantifikasi validitas ringkasan yang dihasilkan oleh model**. Ini membandingkan ringkasan dengan ringkasan \"baseline\" yang biasanya dibuat oleh manusia. Meskipun tidak sempurna, **metrik ini menunjukkan peningkatan keseluruhan dalam efektivitas ringkasan yang telah kita capai dengan fine-tuning.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844e5f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = evaluate.load('rouge')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b6397b",
   "metadata": {},
   "source": [
    "Hasilkan output untuk sampel dataset uji (hanya 10 percakapan dan ringkasan untuk menghemat waktu), dan simpan hasilnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b190f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogues = dataset['test'][0:10]['dialogue']\n",
    "human_baseline_summaries = dataset['test'][0:10]['summary']\n",
    "\n",
    "original_model_summaries = []\n",
    "instruct_model_summaries = []\n",
    "\n",
    "for _, dialogue in enumerate(dialogues):\n",
    "    prompt = f\"\"\"\n",
    "Summarize the following conversation.\n",
    "\n",
    "{dialogue}\n",
    "\n",
    "Summary: \"\"\"\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "    original_model_outputs = original_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200))\n",
    "    original_model_text_output = tokenizer.decode(original_model_outputs[0], skip_special_tokens=True)\n",
    "    original_model_summaries.append(original_model_text_output)\n",
    "\n",
    "    instruct_model_outputs = instruct_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200))\n",
    "    instruct_model_text_output = tokenizer.decode(instruct_model_outputs[0], skip_special_tokens=True)\n",
    "    instruct_model_summaries.append(instruct_model_text_output)\n",
    "    \n",
    "zipped_summaries = list(zip(human_baseline_summaries, original_model_summaries, instruct_model_summaries))\n",
    " \n",
    "df = pd.DataFrame(zipped_summaries, columns = ['human_baseline_summaries', 'original_model_summaries', 'instruct_model_summaries'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2974f22a",
   "metadata": {},
   "source": [
    "Khususnya, mari kita muat ROUGE dan kita akan melihat, saya pikir kita hanya akan melakukan mungkin 10 pertama di sini, dan mari kita bandingkan. **Mari ambil 10 pertama dari dataset uji kami**. Kami akan menjalankannya melalui percakapan ini, melalui **model Flan-T5 asli serta model fine-tuning instruksi yang kita latih di atas**. Di sini, tentu saja, **kami akan membungkusnya dalam prompt yang mirip dengan apa yang kami gunakan untuk pelatihan**. Kemudian mari kita lihat bagaimana hasilnya. Ini adalah cara kualitatif untuk melihat keduanya secara berdampingan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6293bfb0",
   "metadata": {},
   "source": [
    "Evaluasi model dengan menghitung metrik ROUGE. Perhatikan peningkatan hasilnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414dfdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_model_results = rouge.compute(\n",
    "    predictions=original_model_summaries,\n",
    "    references=human_baseline_summaries[0:len(original_model_summaries)],\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")\n",
    "\n",
    "instruct_model_results = rouge.compute(\n",
    "    predictions=instruct_model_summaries,\n",
    "    references=human_baseline_summaries[0:len(instruct_model_summaries)],\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")\n",
    "\n",
    "print('ORIGINAL MODEL:')\n",
    "print(original_model_results)\n",
    "print('INSTRUCT MODEL:')\n",
    "print(instruct_model_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc54cc7",
   "metadata": {},
   "source": [
    "**ORIGINAL MODEL:**\n",
    "\n",
    "{'rouge1': 0.24223171760013867, 'rouge2': 0.10614243734192583, 'rougeL': 0.21380459196706333, 'rougeLsum': 0.21740921541379205}\n",
    "\n",
    "**INSTRUCT MODEL:**\n",
    "\n",
    "{'rouge1': 0.41026607717457186, 'rouge2': 0.17840645241958838, 'rougeL': 0.2977022096267017, 'rougeLsum': 0.2987374187518165}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e573930c",
   "metadata": {},
   "source": [
    "Mari kita bandingkan metrik ROUGE untuk model Flan-T5 asli dan model fine-tune instruksi yang telah kita tuning di atas. Di sini kita melihat bahwa **skor model fine-tune instruksi jauh lebih tinggi pada metrik evaluasi ROUGE daripada model Flan-T5 asli**. Ini menunjukkan bahwa dengan sedikit fine-tuning menggunakan dataset kami dan prompt yang spesifik, kami sebenarnya dapat meningkatkan metrik ROUGE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ebd1a5",
   "metadata": {},
   "source": [
    "File data/dialogue-summary-training-result.csv berisi daftar yang sudah diisi sebelumnya dari semua hasil model yang dapat Anda gunakan untuk mengevaluasi pada sebagian data yang lebih besar. Mari lakukan itu untuk setiap model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6654396b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(\"data/dialogue-summary-training-results.csv\")\n",
    "\n",
    "human_baseline_summaries = results['human_baseline_summaries'].values\n",
    "original_model_summaries = results['original_model_summaries'].values\n",
    "instruct_model_summaries = results['instruct_model_summaries'].values\n",
    "\n",
    "original_model_results = rouge.compute(\n",
    "    predictions=original_model_summaries,\n",
    "    references=human_baseline_summaries[0:len(original_model_summaries)],\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")\n",
    "\n",
    "instruct_model_results = rouge.compute(\n",
    "    predictions=instruct_model_summaries,\n",
    "    references=human_baseline_summaries[0:len(instruct_model_summaries)],\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")\n",
    "\n",
    "print('ORIGINAL MODEL:')\n",
    "print(original_model_results)\n",
    "print('INSTRUCT MODEL:')\n",
    "print(instruct_model_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdaaaa9",
   "metadata": {},
   "source": [
    "**ORIGINAL MODEL:**\n",
    "\n",
    "{'rouge1': 0.2334158581572823, 'rouge2': 0.07603964187010573, 'rougeL': 0.20145520923859048, 'rougeLsum': 0.20145899339006135}\n",
    "\n",
    "**INSTRUCT MODEL:**\n",
    "\n",
    "{'rouge1': 0.42161291557556113, 'rouge2': 0.18035380596301792, 'rougeL': 0.3384439349963909, 'rougeLsum': 0.33835653595561666}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03852aa5",
   "metadata": {},
   "source": [
    "Satu hal lain yang kami lakukan secara offline adalah kami melakukan ini dengan dataset uji yang jauh lebih besar dan lebih lama. Ini bukan hanya 10 atau 15 contoh, sebenarnya ini adalah dataset penuh, dan mari kita lihat. Itu adalah apa yang ada dalam file ini. File CSV yang disertakan dalam direktori data dengan lab ini. **Di sini kita lihat dengan dataset yang jauh lebih besar, skornya masih cukup mirip, di mana kita mendekati dua kali lipat,** meskipun tidak sepenuhnya dua kali lipat dalam beberapa kasus, **tetapi peningkatan cukup signifikan dari Flan-T5 asli.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d360305c",
   "metadata": {},
   "source": [
    "**Hasilnya menunjukkan peningkatan yang signifikan** dalam semua metrik ROUGE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512405d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Absolute percentage improvement of INSTRUCT MODEL over HUMAN BASELINE\")\n",
    "\n",
    "improvement = (np.array(list(instruct_model_results.values())) - np.array(list(original_model_results.values())))\n",
    "for key, value in zip(instruct_model_results.keys(), improvement):\n",
    "    print(f'{key}: {value*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe4ea73",
   "metadata": {},
   "source": [
    "Di sini kita lihat persentase peningkatan secara khusus. Jika kita benar-benar melakukan perhitungan, kita lihat rouge1 18% lebih tinggi, rouge2 10%, rougeL 13, rougeLsum 13,7 juga. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfb1e12",
   "metadata": {},
   "source": [
    "## 3. Perform Parameter Efficient Fine-Tuning (PEFT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1b88b5",
   "metadata": {},
   "source": [
    "Sekarang mari masuk ke fine-tuning parameter yang efisien (PEFT). Ini membuat perbedaan besar, terutama ketika Anda dibatasi oleh seberapa banyak sumber daya komputasi yang Anda miliki, Anda **dapat menurunkan jejaknya baik memori, disk, GPU, CPU, semua sumber daya dapat dikurangi hanya dengan memperkenalkan PEFT ke dalam proses fine-tuning Anda**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb151d8",
   "metadata": {},
   "source": [
    "### 3.1. Setup the PEFT /LoRA model for Fine-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3deef284",
   "metadata": {},
   "source": [
    "Anda perlu menyiapkan model PEFT/LoRA untuk fine-tuning dengan lapisan/parameter adapter baru. **Menggunakan PEFT/LoRA, Anda membekukan LLM yang mendasari dan hanya melatih adapter.** Lihat konfigurasi **LoRA** di bawah ini. Perhatikan **hyperparameter rank (r)**, yang mendefinisikan **rank/dimensi adapter yang akan dilatih.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd44320",
   "metadata": {},
   "source": [
    "Dalam pelajaran Anda belajar tentang **LoRA**, Anda belajar tentang **peringkat (rank)**. Di sini kita akan memilih peringkat 32, yang sebenarnya relatif tinggi. Tapi kita baru saja mulai dengan itu. Di sini adalah **SEQ_2_SEQ_LM**, ini adalah **FLAN-T5**. Dengan hanya beberapa baris kode ekstra di sini untuk **mengonfigurasi fine-tuning LoRA** kami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728186a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=32, # Rank\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q\", \"v\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM # FLAN-T5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bbb8b1",
   "metadata": {},
   "source": [
    "**Tambahkan lapisan/parameter adapter LoRA ke LLM asli untuk dilatih.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c2ea57",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_model = get_peft_model(original_model,\n",
    "                           lora_config)\n",
    "print(print_number_of_trainable_model_parameters(peft_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1212e11",
   "metadata": {},
   "source": [
    "trainable model parameters: 3538944\n",
    "\n",
    "all model parameters: 251116800\n",
    "\n",
    "percentage of trainable model parameters: 1.41%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fac505",
   "metadata": {},
   "source": [
    "Kemudian di sini kita hanya akan **melatih 1,4 persen dari parameter model yang dapat dilatih.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1d5188",
   "metadata": {},
   "source": [
    "Dalam banyak kasus, Anda dapat fine-tuning model yang sangat besar pada satu GPU. Berikut adalah beberapa argumen pelatihan tersebut. Ini kembali ke argumen pelatihan asli dari hugging face, kecuali **daripada hanya menggunakan model biasa, kami sebenarnya menggunakan model PEFT.** Di sini ini adalah fungsi kenyamanan yang ditawarkan oleh perpustakaan PEFT dan **kami memberikan model asli, yang merupakan FLAN-T5.** Kami memberikan **konfigurasi LoRA** yang kita tentukan di atas dengan Peringkat 32. Kami katakan berikan saya versi PEFT dari model itu. Itu keluar sebagai 1,4 persen. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9eef31",
   "metadata": {},
   "source": [
    "### 3.2 Train PEFT Adapter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56692a6",
   "metadata": {},
   "source": [
    "Sekarang kita lakukan argumen pelatihan. Sekali lagi, jumlah langkah yang kecil, jumlah epoch yang kecil di sini. Kami memiliki versi yang dilatih secara offline. Itu sedikit lebih baik daripada yang ada di lab ini secara khusus, dan itulah yang akan kita unduh di sini dalam beberapa saat. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31494644",
   "metadata": {},
   "source": [
    "**Definisikan argumen pelatihan dan buat instance Trainer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288ab024",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = f'./peft-dialogue-summary-training-{str(int(time.time()))}'\n",
    "\n",
    "peft_training_largs = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    auto_find_batch_size=True,\n",
    "    learning_rate=1e-3, #higher learning rate than full fine-tuning.\n",
    "    num_train_epochs=1, \n",
    "    logging_steps=1,\n",
    "    max_steps=1\n",
    ")\n",
    "\n",
    "peft_trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=peft_training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2e5bd7",
   "metadata": {},
   "source": [
    "Sekarang semuanya sudah **siap untuk melatih adapter PEFT dan menyimpan model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8ca7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_trainer.train()\n",
    "\n",
    "peft_model_path=\"./peft-dialogue-summary-checkpoint-local\"\n",
    "\n",
    "peft_trainer.model.save_pretrained(peft_model_path)\n",
    "tokenizer.save_pretrained(peft_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a039cab",
   "metadata": {},
   "source": [
    "Mari kita lakukan itu. Inilah **model lain yang disimpan dalam penyimpanan cloud S3.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7114763",
   "metadata": {},
   "outputs": [],
   "source": [
    "('./peft-dialogue-summary-checkpoint-local/tokenizer_config.json',\n",
    " './peft-dialogue-summary-checkpoint-local/special_tokens',\n",
    " './peft-dialogue-summary-checkpoint-local/tokenizer.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a18984",
   "metadata": {},
   "source": [
    "Pelatihan tersebut dilakukan pada subset data. Untuk memuat model PEFT yang sudah dilatih sepenuhnya, baca checkpoint model PEFT dari S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c468e1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp --recursive s3://dlai-generative-ai/models/peft-dialogue-summary-checkpoint/ ./peft-dialogue-summary-checkpoint-from-s3/ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6e0e8f",
   "metadata": {},
   "source": [
    "**Pastikan ukuran model ini jauh lebih kecil dibandingkan LLM asli.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5779dead",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -al ./peft-dialogue-summary-checkpoint-from-s3/adapter_model.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee0e206",
   "metadata": {},
   "source": [
    "Sekarang kita melihat ini hanya 14 megabyte. Ini disebut sebagai **adapter PEFT atau pengadopsi LoRA.** Ini digabungkan atau digabungkan dengan LLM asli. Ketika Anda benar-benar melayani model ini, yang akan kita dengar dalam waktu dekat, Anda harus **mengambil LLM asli dan kemudian menggabungkan adapter PEFT LoRA ini.** **Ini jauh lebih kecil dan Anda dapat menggunakan kembali LLM dasar yang sama dan menukar adapter PEFT yang berbeda jika diperlukan.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a1f22d",
   "metadata": {},
   "source": [
    "**Siapkan model ini dengan menambahkan adapter ke model FLAN-T5 asli.** Anda mengatur is_trainable=False karena rencana hanya melakukan inferensi dengan model PEFT ini. Jika Anda menyiapkan model untuk pelatihan lebih lanjut, Anda akan mengatur is_trainable=True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bfa47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "peft_model_base = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\", torch_dtype=torch.bfloat16)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")\n",
    "\n",
    "peft_model = PeftModel.from_pretrained(peft_model_base,\n",
    "                                      './peft-dialogue-summary-checkpoint-from-s3',\n",
    "                                      torch_dtype=torch.bfloat16,\n",
    "                                      is_trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6791d7d",
   "metadata": {},
   "source": [
    "The number of trainable parameters will be 0 due to is_trainable=False setting:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cf5733",
   "metadata": {},
   "source": [
    "Sekarang s**etelah kita memiliki adapter PEFT disalin dari S3, kita akan menggabungkannya dengan LLM asli, yaitu FLAN-T5, dan menggunakan itu untuk melakukan summarisasi.** Satu hal yang perlu ditekankan yang tidak sepenuhnya jelas adalah bahwa saat kita melakukan ini, saya sebenarnya dapat mengatur flag is_trainable menjadi false. **Dengan mengatur flag is_trainable menjadi false, kita memberi tahu PyTorch bahwa kita tidak tertarik untuk melatih model ini. Yang kami minati hanyalah langkah maju hanya untuk mendapatkan ringkasan.** Ini penting karena kita dapat memberi tahu PyTorch untuk tidak memuat bagian pembaruan dari operator-operator ini dan pada dasarnya meminimalkan jejak yang dibutuhkan untuk hanya melakukan inferensi dengan model ini. Ini adalah bendera yang cukup bagus. Ini sebenarnya baru saja diperkenalkan baru-baru ini ke dalam model PEFT pada saat lab ini. Saya ingin menunjukkannya di sini karena ini adalah pola yang ingin Anda coba temukan saat Anda melakukan pemodelan Anda sendiri. **Ketika Anda tahu bahwa Anda siap untuk mendeploy model untuk inferensi, biasanya ada cara di mana Anda dapat memberi petunjuk kepada kerangka kerja, seperti PyTorch bahwa Anda tidak akan melakukan pelatihan. Ini kemudian dapat lebih mengurangi sumber daya yang dibutuhkan untuk membuat prediksi ini.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b1a3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(print_number_of_trainable_model_parameters(peft_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5657ec8",
   "metadata": {},
   "source": [
    "trainable model parameters: 0\n",
    "\n",
    "all model parameters: 251116800\n",
    "\n",
    "percentage of trainable model parameters: 0.00%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b7810c",
   "metadata": {},
   "source": [
    "Di sini, hanya untuk menekankannya, saya **mencetak jumlah parameter yang dapat dilatih.** Ingatlah bahwa pada titik ini **kita hanya berencana untuk melakukan inferensi**, dan mari kita lanjutkan. 0 % dari parameter yang dapat dilatih ini."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1d7a62",
   "metadata": {},
   "source": [
    "### 3.3. Evaluate the Model Qualitative (Human Evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df912f8",
   "metadata": {},
   "source": [
    "Lakukan inferensi untuk contoh yang sama seperti pada bagian 1.3 dan 2.3, dengan model asli, *fully fine-tuned*, dan model PEFT."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5347d319",
   "metadata": {},
   "source": [
    "Di sini, kita akan membuat beberapa contoh prompt dari dataset uji kami. Kita hanya akan memilih sesuatu secara acak di sini, pada dasarnya Indeks 200. Kita akan melihat model instruksi. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47039aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 200\n",
    "dialogue = dataset['test'][index]['dialogue']\n",
    "baseline_human_summary = dataset['test'][index]['summary']\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Summarize the following conversation.\n",
    "\n",
    "{dialogue}\n",
    "\n",
    "Summary: \"\"\"\n",
    "\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "original_model_outputs = original_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200, num_beams=1))\n",
    "original_model_text_output = tokenizer.decode(original_model_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "instruct_model_outputs = instruct_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200, num_beams=1))\n",
    "instruct_model_text_output = tokenizer.decode(instruct_model_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "peft_model_outputs = peft_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200, num_beams=1))\n",
    "peft_model_text_output = tokenizer.decode(peft_model_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{human_baseline_summary}')\n",
    "print(dash_line)\n",
    "print(f'ORIGINAL MODEL:\\n{original_model_text_output}')\n",
    "print(dash_line)\n",
    "print(f'INSTRUCT MODEL:\\n{instruct_model_text_output}')\n",
    "print(dash_line)\n",
    "print(f'PEFT MODEL: {peft_model_text_output}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffb4cea",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------\n",
    "**BASELINE HUMAN SUMMARY:**\n",
    "\n",
    "#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n",
    "\n",
    "**ORIGINAL MODEL:**\n",
    "\n",
    "#Pork1: Have you considered upgrading your system? #Person1: Yes, but I'd like to make some improvements. #Pork1: I'd like to make a painting program. #Person1: I'd like to make a flyer. #Pork2: I'd like to make banners. #Person1: I'd like to make a computer graphics program. #Person2: I'd like to make a computer graphics program. #Person1: I'd like to make a computer graphics program. #Person2: Is there anything else you'd like to do? #Person1: I'd like to make a computer graphics program. #Person2: Is there anything else you need? #Person1: I'd like to make a computer graphics program. #Person2: I'\n",
    "\n",
    "**INSTRUCT MODEL:**\n",
    "\n",
    "#Person1# suggests #Person2# upgrading #Person2#'s system, hardware, and CD-ROM drive. #Person2# thinks it's great.\n",
    "\n",
    "**PEFT MODEL:**\n",
    "\n",
    "#Person1# recommends adding a painting program to #Person2#'s software and upgrading hardware. #Person2# also wants to upgrade the hardware because it's outdated now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9234a7",
   "metadata": {},
   "source": [
    "Mengerti. Sebagian besar benar saya kira, model PEFT menemukan sedikit lebih banyak nuansa di sini. Tetapi sebenarnya, seperti yang akan kita lihat secara kualitatif ketika kita menjalankan metrik rouge. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca13ce84",
   "metadata": {},
   "source": [
    "### 3.4. Evaluate the Model Quantitatively (with ROUGE Metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1306ccf6",
   "metadata": {},
   "source": [
    "Lakukan inferensi untuk sampel dari data uji (hanya 10 dialog dan ringkasan untuk menghemat waktu)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93723730",
   "metadata": {},
   "source": [
    "Di sini kita akan **membandingkan baseline manusia dengan FLAN-T5 asli dengan full fine-tuned instruksi, dan kemudian dengan PEFT fine-tuned.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f0baad",
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogues = dataset['test'][0:10]['dialogue']\n",
    "human_baseline_summaries = dataset['test'][0:10]['summary']\n",
    "\n",
    "original_model_summaries = []\n",
    "instruct_model_summaries = []\n",
    "peft_model_summaries = []\n",
    "\n",
    "for idx, dialogue in enumerate(dialogues):\n",
    "    prompt = f\"\"\"\n",
    "Summarize the following conversation.\n",
    "\n",
    "{dialogue}\n",
    "\n",
    "Summary: \"\"\"\n",
    "    \n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "    human_baseline_text_output = human_baseline_summaries[idx]\n",
    "    \n",
    "    original_model_outputs = original_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200))\n",
    "    original_model_text_output = tokenizer.decode(original_model_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    instruct_model_outputs = instruct_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200))\n",
    "    instruct_model_text_output = tokenizer.decode(instruct_model_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    peft_model_outputs = peft_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200))\n",
    "    peft_model_text_output = tokenizer.decode(peft_model_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    original_model_summaries.append(original_model_text_output)\n",
    "    instruct_model_summaries.append(instruct_model_text_output)\n",
    "    peft_model_summaries.append(peft_model_text_output)\n",
    "\n",
    "zipped_summaries = list(zip(human_baseline_summaries, original_model_summaries, instruct_model_summaries, peft_model_summaries))\n",
    " \n",
    "df = pd.DataFrame(zipped_summaries, columns = ['human_baseline_summaries', 'original_model_summaries', 'instruct_model_summaries', 'peft_model_summaries'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e4225c",
   "metadata": {},
   "source": [
    "Sebagian besar, hanya sekilas di sini, sepertinya ini cukup mirip. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff66e74",
   "metadata": {},
   "source": [
    " Tapi mari kita lihat **metrik rouge** dan lihat apa yang terjadi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ffd678",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = evaluate.load('rouge')\n",
    "\n",
    "original_model_results = rouge.compute(\n",
    "    predictions=original_model_summaries,\n",
    "    references=human_baseline_summaries[0:len(original_model_summaries)],\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")\n",
    "\n",
    "instruct_model_results = rouge.compute(\n",
    "    predictions=instruct_model_summaries,\n",
    "    references=human_baseline_summaries[0:len(instruct_model_summaries)],\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")\n",
    "\n",
    "peft_model_results = rouge.compute(\n",
    "    predictions=peft_model_summaries,\n",
    "    references=human_baseline_summaries[0:len(peft_model_summaries)],\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")\n",
    "\n",
    "print('ORIGINAL MODEL:')\n",
    "print(original_model_results)\n",
    "print('INSTRUCT MODEL:')\n",
    "print(instruct_model_results)\n",
    "print('PEFT MODEL:')\n",
    "print(peft_model_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2faa9ecb",
   "metadata": {},
   "source": [
    "**ORIGINAL MODEL:**\n",
    "\n",
    "{'rouge1': 0.2127769756385947, 'rouge2': 0.07849999999999999, 'rougeL': 0.1803101433337705, 'rougeLsum': 0.1872151390166362}\n",
    "\n",
    "**INSTRUCT MODEL:**\n",
    "\n",
    "{'rouge1': 0.41026607717457186, 'rouge2': 0.17840645241958838, 'rougeL': 0.2977022096267017, 'rougeLsum': 0.2987374187518165}\n",
    "\n",
    "**PEFT MODEL:**\n",
    "\n",
    "{'rouge1': 0.3725351062275605, 'rouge2': 0.12138811933618107, 'rougeL': 0.27620639623170606, 'rougeLsum': 0.2758134870822362}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d87e356",
   "metadata": {},
   "source": [
    "Di sini kita lihat **model fine-tuned instruksi adalah peningkatan yang cukup drastis dibandingkan dengan FLAN-T5 asli.** Kita melihat bahwa **model PEFT mengalami sedikit degradasi dari full fine-tuned.** Ini cukup dekat dalam beberapa kasus. Itu tidak terlalu buruk. Tetapi **kita menggunakan sumber daya yang jauh lebih sedikit selama fine-tuning, daripada yang akan kita miliki jika kita melakukan instruksi penuh.** Anda dapat membayangkan ini hanya beberapa ribu sampel, tetapi Anda dapat membayangkan dalam skala besar bagaimana ini benar-benar dapat menghemat banyak sumber daya komputasi dan waktu dengan menggunakan PEFT dengan melihat dataset yang lebih besar. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695dde2f",
   "metadata": {},
   "source": [
    "Perhatikan bahwa **hasil model PEFT tidak terlalu buruk, sementara proses pelatihannya jauh lebih mudah!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65eafd5",
   "metadata": {},
   "source": [
    "Anda sudah menghitung skor ROUGE pada seluruh dataset, setelah memuat hasil dari file data/dialogue-summary-training-results.csv. Sekarang, **muat nilai untuk model PEFT dan periksa kinerjanya dibandingkan dengan model lain.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4829921",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_baseline_summaries = results['human_baseline_summaries'].values\n",
    "original_model_summaries = results['original_model_summaries'].values\n",
    "instruct_model_summaries = results['instruct_model_summaries'].values\n",
    "peft_model_summaries     = results['peft_model_summaries'].values\n",
    "\n",
    "original_model_results = rouge.compute(\n",
    "    predictions=original_model_summaries,\n",
    "    references=human_baseline_summaries[0:len(original_model_summaries)],\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")\n",
    "\n",
    "instruct_model_results = rouge.compute(\n",
    "    predictions=instruct_model_summaries,\n",
    "    references=human_baseline_summaries[0:len(instruct_model_summaries)],\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")\n",
    "\n",
    "peft_model_results = rouge.compute(\n",
    "    predictions=peft_model_summaries,\n",
    "    references=human_baseline_summaries[0:len(peft_model_summaries)],\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")\n",
    "\n",
    "print('ORIGINAL MODEL:')\n",
    "print(original_model_results)\n",
    "print('INSTRUCT MODEL:')\n",
    "print(instruct_model_results)\n",
    "print('PEFT MODEL:')\n",
    "print(peft_model_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fe9961",
   "metadata": {},
   "source": [
    "**ORIGINAL MODEL:**\n",
    "\n",
    "{'rouge1': 0.2334158581572823, 'rouge2': 0.07603964187010573, 'rougeL': 0.20145520923859048, 'rougeLsum': 0.20145899339006135}\n",
    "\n",
    "**INSTRUCT MODEL:**\n",
    "\n",
    "{'rouge1': 0.42161291557556113, 'rouge2': 0.18035380596301792, 'rougeL': 0.3384439349963909, 'rougeLsum': 0.33835653595561666}\n",
    "\n",
    "**PEFT MODEL:**\n",
    "\n",
    "{'rouge1': 0.40810631575616746, 'rouge2': 0.1633255794568712, 'rougeL': 0.32507074586565354, 'rougeLsum': 0.3248950182867091}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48679f64",
   "metadata": {},
   "source": [
    "**Hasil menunjukkan peningkatan yang lebih rendah dibandingkan dengan pelatihan penuh, tetapi manfaat PEFT biasanya lebih besar daripada sedikit penurunan metrik kinerja.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00f54fe",
   "metadata": {},
   "source": [
    "Hitung peningkatan PEFT dibandingkan dengan model asli:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6baa679",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Absolute percentage improvement of PEFT MODEL over HUMAN BASELINE\")\n",
    "\n",
    "improvement = (np.array(list(peft_model_results.values())) - np.array(list(original_model_results.values())))\n",
    "for key, value in zip(peft_model_results.keys(), improvement):\n",
    "    print(f'{key}: {value*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70198986",
   "metadata": {},
   "source": [
    "Absolute percentage improvement of PEFT MODEL over HUMAN BASELINE\n",
    "\n",
    "rouge1: 17.47%\n",
    "\n",
    "rouge2: 8.73%\n",
    "\n",
    "rougeL: 12.36%\n",
    "\n",
    "rougeLsum: 12.34%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99fa19b",
   "metadata": {},
   "source": [
    "Di atas, saya hanya melihat mungkin 10, 15 contoh. Di sini kita lihat yang lebih besar. Sepertinya saya pikir saya memiliki ini **di sini rouge satu, PEFT kehilangan sekitar satu hingga mungkin 1,7 persen di seluruh metrik rouge ini.** Itu tidak buruk relatif terhadap penghematan yang Anda dapatkan saat menggunakan PEFT."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6bf573",
   "metadata": {},
   "source": [
    "Hitung **peningkatan PEFT dibandingkan dengan model yang sepenuhnya disempurnakan**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dc7306",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Absolute percentage improvement of PEFT MODEL over INSTRUCT MODEL\")\n",
    "\n",
    "improvement = (np.array(list(peft_model_results.values())) - np.array(list(instruct_model_results.values())))\n",
    "for key, value in zip(peft_model_results.keys(), improvement):\n",
    "    print(f'{key}: {value*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b49e77",
   "metadata": {},
   "source": [
    "Absolute percentage improvement of PEFT MODEL over INSTRUCT MODEL\n",
    "\n",
    "rouge1: -1.35%\n",
    "\n",
    "rouge2: -1.70%\n",
    "\n",
    "rougeL: -1.34%\n",
    "\n",
    "rougeLsum: -1.35%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f063cd9",
   "metadata": {},
   "source": [
    "Di sini, Anda melihat sedikit **penurunan persentase pada metrik ROUGE dibandingkan dengan model full fine-tuning.** Namun, **pelatihan membutuhkan jauh lebih sedikit sumber daya komputasi dan memori (seringkali hanya membutuhkan satu GPU).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bd7612",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
