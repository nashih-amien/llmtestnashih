{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2ce0e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\nashih amien\\anaconda3\\lib\\site-packages (4.27.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\nashih amien\\anaconda3\\lib\\site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in c:\\users\\nashih amien\\anaconda3\\lib\\site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\nashih amien\\anaconda3\\lib\\site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\nashih amien\\anaconda3\\lib\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\nashih amien\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\nashih amien\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in c:\\users\\nashih amien\\anaconda3\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\nashih amien\\anaconda3\\lib\\site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\nashih amien\\anaconda3\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\nashih amien\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\nashih amien\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.10.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\nashih amien\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nashih amien\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nashih amien\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nashih amien\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nashih amien\\anaconda3\\lib\\site-packages (from requests->transformers) (2023.7.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: datasets in c:\\users\\nashih amien\\anaconda3\\lib\\site-packages (2.11.0)\n",
      "Collecting datasets\n",
      "  Downloading datasets-2.18.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\nashih amien\\anaconda3\\lib\\site-packages (from datasets) (3.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\nashih amien\\anaconda3\\lib\\site-packages (from datasets) (1.24.3)\n",
      "Collecting pyarrow>=12.0.0 (from datasets)\n",
      "  Downloading pyarrow-15.0.2-cp311-cp311-win_amd64.whl.metadata (3.1 kB)\n",
      "Collecting pyarrow-hotfix (from datasets)\n",
      "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\nashih amien\\anaconda3\\lib\\site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in c:\\users\\nashih amien\\anaconda3\\lib\\site-packages (from datasets) (2.0.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\nashih amien\\anaconda3\\lib\\site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\nashih amien\\anaconda3\\lib\\site-packages (from datasets) (4.65.0)\n",
      "Requirement already satisfied: xxhash in c:\\users\\nashih amien\\anaconda3\\lib\\site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\nashih amien\\anaconda3\\lib\\site-packages (from datasets) (0.70.14)\n",
      "Collecting fsspec<=2024.2.0,>=2023.1.0 (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2024.2.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\nashih amien\\anaconda3\\lib\\site-packages (from datasets) (3.8.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in c:\\users\\nashih amien\\anaconda3\\lib\\site-packages (from datasets) (0.22.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\nashih amien\\anaconda3\\lib\\site-packages (from datasets) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\nashih amien\\anaconda3\\lib\\site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\nashih amien\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\nashih amien\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\nashih amien\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\nashih amien\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\nashih amien\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\nashih amien\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\nashih amien\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\nashih amien\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.19.4->datasets) (4.10.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nashih amien\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nashih amien\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nashih amien\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\nashih amien\\anaconda3\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\nashih amien\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nashih amien\\anaconda3\\lib\\site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\nashih amien\\anaconda3\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nashih amien\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
      "   ---------------------------------------- 0.0/510.5 kB ? eta -:--:--\n",
      "   ------ --------------------------------- 81.9/510.5 kB 2.3 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 81.9/510.5 kB 2.3 MB/s eta 0:00:01\n",
      "   ------- ------------------------------- 92.2/510.5 kB 744.7 kB/s eta 0:00:01\n",
      "   ---------- --------------------------- 143.4/510.5 kB 853.3 kB/s eta 0:00:01\n",
      "   -------------- ----------------------- 194.6/510.5 kB 908.0 kB/s eta 0:00:01\n",
      "   -------------------------------- ------- 409.6/510.5 kB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 510.5/510.5 kB 1.7 MB/s eta 0:00:00\n",
      "Downloading fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
      "   ---------------------------------------- 0.0/170.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 170.9/170.9 kB 5.2 MB/s eta 0:00:00\n",
      "Downloading pyarrow-15.0.2-cp311-cp311-win_amd64.whl (24.8 MB)\n",
      "   ---------------------------------------- 0.0/24.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.2/24.8 MB 6.9 MB/s eta 0:00:04\n",
      "    --------------------------------------- 0.5/24.8 MB 5.9 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 0.7/24.8 MB 5.8 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 1.0/24.8 MB 5.7 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 1.2/24.8 MB 5.6 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 1.4/24.8 MB 5.4 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 1.5/24.8 MB 5.5 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 1.6/24.8 MB 4.6 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 1.8/24.8 MB 4.6 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 2.0/24.8 MB 4.5 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 2.2/24.8 MB 4.6 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 2.4/24.8 MB 4.4 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 2.6/24.8 MB 4.4 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 2.8/24.8 MB 4.5 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 3.0/24.8 MB 4.4 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 3.3/24.8 MB 4.5 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 3.6/24.8 MB 4.6 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 3.8/24.8 MB 4.6 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 4.1/24.8 MB 4.7 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 4.4/24.8 MB 4.8 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 4.8/24.8 MB 4.9 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 5.1/24.8 MB 5.0 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 5.4/24.8 MB 5.1 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 5.7/24.8 MB 5.1 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 6.0/24.8 MB 5.2 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 6.4/24.8 MB 5.3 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 6.7/24.8 MB 5.3 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 7.0/24.8 MB 5.4 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 7.3/24.8 MB 5.4 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 7.6/24.8 MB 5.4 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 7.8/24.8 MB 5.4 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 8.2/24.8 MB 5.5 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 8.5/24.8 MB 5.5 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 8.8/24.8 MB 5.6 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 9.2/24.8 MB 5.6 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 9.5/24.8 MB 5.7 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 9.8/24.8 MB 5.7 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 10.1/24.8 MB 5.7 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 10.4/24.8 MB 5.7 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 10.6/24.8 MB 5.7 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 10.9/24.8 MB 5.7 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 11.2/24.8 MB 5.7 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 11.5/24.8 MB 5.7 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 11.8/24.8 MB 6.0 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 12.1/24.8 MB 6.1 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 12.4/24.8 MB 6.1 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 12.6/24.8 MB 6.2 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 12.9/24.8 MB 6.2 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 13.2/24.8 MB 6.4 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 13.4/24.8 MB 6.3 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 13.7/24.8 MB 6.4 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 14.0/24.8 MB 6.5 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 14.3/24.8 MB 6.4 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 14.6/24.8 MB 6.4 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 14.6/24.8 MB 6.4 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 14.8/24.8 MB 6.1 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 15.0/24.8 MB 6.1 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 15.5/24.8 MB 6.2 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 15.8/24.8 MB 6.2 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 16.2/24.8 MB 6.2 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 16.6/24.8 MB 6.2 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 16.9/24.8 MB 6.2 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 17.2/24.8 MB 6.2 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 17.4/24.8 MB 6.2 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 17.7/24.8 MB 6.2 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 18.0/24.8 MB 6.2 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 18.3/24.8 MB 6.2 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 18.6/24.8 MB 6.2 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 18.9/24.8 MB 6.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 19.1/24.8 MB 6.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 19.4/24.8 MB 6.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 19.7/24.8 MB 6.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 20.0/24.8 MB 6.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 20.3/24.8 MB 6.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 20.6/24.8 MB 6.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 20.8/24.8 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 21.1/24.8 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 21.4/24.8 MB 6.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 21.7/24.8 MB 6.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 22.0/24.8 MB 6.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 22.3/24.8 MB 6.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 22.6/24.8 MB 6.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 22.9/24.8 MB 6.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 23.1/24.8 MB 6.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 23.4/24.8 MB 6.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 23.7/24.8 MB 6.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 24.0/24.8 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.3/24.8 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.6/24.8 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.8/24.8 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.8/24.8 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 24.8/24.8 MB 6.0 MB/s eta 0:00:00\n",
      "Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Installing collected packages: pyarrow-hotfix, pyarrow, fsspec, datasets\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 11.0.0\n",
      "    Uninstalling pyarrow-11.0.0:\n",
      "      Successfully uninstalled pyarrow-11.0.0\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.3.1\n",
      "    Uninstalling fsspec-2024.3.1:\n",
      "      Successfully uninstalled fsspec-2024.3.1\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 2.11.0\n",
      "    Uninstalling datasets-2.11.0:\n",
      "      Successfully uninstalled datasets-2.11.0\n",
      "Successfully installed datasets-2.18.0 fsspec-2024.2.0 pyarrow-15.0.2 pyarrow-hotfix-0.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Nashih Amien\\anaconda3\\Lib\\site-packages\\~yarrow'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "s3fs 2023.4.0 requires fsspec==2023.4.0, but you have fsspec 2024.2.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers\n",
    "%pip install -U datasets\n",
    "    #ransformers \\\n",
    "    #atasets  --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79e85f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import GenerationConfig\n",
    "from transformers import BertTokenizer, AutoModel, EncoderDecoderModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bfc005",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "624f6534",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 74.1M/74.1M [00:16<00:00, 4.58MB/s]\n",
      "Downloading data: 100%|██████████| 8.07M/8.07M [00:04<00:00, 1.97MB/s]\n",
      "Downloading data: 100%|██████████| 7.95M/7.95M [00:13<00:00, 589kB/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afd7d06bc9524e74bb413c026edf3201",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/38242 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c2e151b2a014ba2aac98325cca450f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/4780 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38b20fb6275d4a41b5fb14c91d664025",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/4780 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "huggingface_dataset_name = \"csebuetnlp/xlsum\"\n",
    "dataset = load_dataset(huggingface_dataset_name,'indonesian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea6c09d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "Example 1\n",
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT DIALOGUE:\n",
      "Penjaga pantai berupaya untuk menyelamatkan korban, tujuh orang dilarikan ke rumah sakit Penjara pantai Korea Selatan mengatakan dua orang masih hilang, dan upaya pencarian masih dilakukan. Kapal memancing sewaan, Seonchang-1, membawa 20 penumpang dan dua kru dalam sebuah tur memancing saat tabrakan terjadi. Cuplikan gambar dari lokasi kejadian menunjukkan para penyelam sedang mencari korban perahu yang terbalik. Helikopter Angkatan Laut dan puluhan kapal lain ikut dalam pencarian di Incheon, yang terletak dekat pulau Yeongheung. Tujuh orang dibawa ke rumah sakit untuk mendapatkan perawatan. Kapten kapal memancing berukuran 10 ton itu masih hilang, menurut salah satu laporan AFP. Tidak ada laporan korban luka dari kru kapan tanker dengan ukuran 336-ton tersebut. Kantor berita Korea Selatan Yonhap mengatakan tabrakan terjadi sembilan menit setelah kapal berangkat dari pantai, kemungkinan ketika dua kapal itu bertemu di bawah sebuah jembatan. \"Tidak ada masalah dengan kondisi cuaca, laporan pelayaran atau persiapan lainnya (pra-keberangkatan),\" kata seorang petugas penjaga pantai kepada wartawan. \"Kami menginvestigasi bagaimana kecelakaan terjadi.\" Temperatur air yang dingin mungkin juga menyebabkan korban jiwa, jelas petugas pantai. Kecelakaan ini merupakan yang terburuk di Korea Selatan sejak insiden tur memancing di dekat pulau Jeju yang menyebabkan 15 orang tewas pada 2015 lalu. Setahun sebelumnya, sebuah kapal feri penumpang terbalik dan menyebabkan 300 orang meninggal, sebagian besar dari mereka anak-anak sekolah yang tengah piknik.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "Sedikitnya 13 orang tewas setelah sebuah kapal memancing tabrakan dengan tanker dengan ukuran 336-ton dan terbalik di pantai Korea Selatan.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Example 2\n",
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT DIALOGUE:\n",
      "Vincent Tan sering terlihat memakai kaca mata gelap dan sarung tangan. Tan juga menegaskan bahwa dirinya 'bukan orang yang jahat'. \"Sebaik apa pun Anda, pasti akan ada beberapa orang yang tidak mendukung Anda,\" kata Tan dalam wawancara khusus dengan BBC Sport. Tan diserang mulai dari caranya menjalankan klub hingga kebiasaannya memakai kacamata gelap dan sarung tangan saat menonton pertandingan Cardiff, yang membuat beberapa pendukung Cardiff menyebut Tan tidak ubahnya tokoh antagonis di film-film James Bond. Dalam wawancara dengan BBC, Tan menjawab serangan tersebut. \"Saya memakai kacamata karena silau. Saya memakai sarung tangan karena cuaca sangat dingin (bila dibandingkan dengan cuaca di Malaysia). Jujur saja komentar soal kacamata dan sarung tangan ini sudah sangat berlebihan,\" kata Tan. \"Media di Inggris juga tidak adil ... mungkin karena kami juga tidak memberi penjelasan. Pada saatnya nanti saya akan jelaskan semuanya. Media di Inggris kadang sedikit rasis,\" kata Tan. Tan membeli Cardiff pada 2010 dan di bawah kepemimpinannya Cardiff berhasil masuk ke Liga Primer. Namun ia juga dikecam karena mengubah warna klub -dari biru ke merah- dan memecat manajer yang populer di kalangan suporter.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "Pemilik klub Cardiff City asal Malaysia, Vincent Tan, menegaskan bahwa ia tidak layak disebut sebagai musuh besar para penggemar klub.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_indices =[40,200]\n",
    "dash_line = '-'.join('' for x in range(100))\n",
    "\n",
    "for i, index in enumerate(example_indices):\n",
    "    print(dash_line)\n",
    "    print('Example', i+1)\n",
    "    print(dash_line)\n",
    "    print('INPUT DIALOGUE:')\n",
    "    print(dataset['test'][index]['text'])\n",
    "    print(dash_line)\n",
    "    print('BASELINE HUMAN SUMMARY:')\n",
    "    print(dataset['test'][index]['summary'])\n",
    "    print(dash_line)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "acd7219b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "181adb8fbcf546569af4afe97d7f1a6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.08G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name='cahya/bert2gpt-indonesian-summarization'\n",
    "\n",
    "model = EncoderDecoderModel.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "468344d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(model_name, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff7b23cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Sentence:\n",
      "tensor([    3, 12462,  6900,  1744,  2623,    15,  4257,    32,     1])\n",
      "Decoded Sentence:\n",
      "what time is it, tom?\n"
     ]
    }
   ],
   "source": [
    "sentence = \"What time is it, Tom?\"\n",
    "\n",
    "sentence_encoded = tokenizer(sentence, return_tensors='pt')\n",
    "\n",
    "sentence_decoded = tokenizer.decode(\n",
    "        sentence_encoded[\"input_ids\"][0],\n",
    "        skip_special_tokens=True)\n",
    "\n",
    "print('Encoded Sentence:')\n",
    "print(sentence_encoded[\"input_ids\"][0])\n",
    "print('Decoded Sentence:')\n",
    "print(sentence_decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f29ed7c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "Example 1\n",
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "Penjaga pantai berupaya untuk menyelamatkan korban, tujuh orang dilarikan ke rumah sakit Penjara pantai Korea Selatan mengatakan dua orang masih hilang, dan upaya pencarian masih dilakukan. Kapal memancing sewaan, Seonchang-1, membawa 20 penumpang dan dua kru dalam sebuah tur memancing saat tabrakan terjadi. Cuplikan gambar dari lokasi kejadian menunjukkan para penyelam sedang mencari korban perahu yang terbalik. Helikopter Angkatan Laut dan puluhan kapal lain ikut dalam pencarian di Incheon, yang terletak dekat pulau Yeongheung. Tujuh orang dibawa ke rumah sakit untuk mendapatkan perawatan. Kapten kapal memancing berukuran 10 ton itu masih hilang, menurut salah satu laporan AFP. Tidak ada laporan korban luka dari kru kapan tanker dengan ukuran 336-ton tersebut. Kantor berita Korea Selatan Yonhap mengatakan tabrakan terjadi sembilan menit setelah kapal berangkat dari pantai, kemungkinan ketika dua kapal itu bertemu di bawah sebuah jembatan. \"Tidak ada masalah dengan kondisi cuaca, laporan pelayaran atau persiapan lainnya (pra-keberangkatan),\" kata seorang petugas penjaga pantai kepada wartawan. \"Kami menginvestigasi bagaimana kecelakaan terjadi.\" Temperatur air yang dingin mungkin juga menyebabkan korban jiwa, jelas petugas pantai. Kecelakaan ini merupakan yang terburuk di Korea Selatan sejak insiden tur memancing di dekat pulau Jeju yang menyebabkan 15 orang tewas pada 2015 lalu. Setahun sebelumnya, sebuah kapal feri penumpang terbalik dan menyebabkan 300 orang meninggal, sebagian besar dari mereka anak-anak sekolah yang tengah piknik.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "Sedikitnya 13 orang tewas setelah sebuah kapal memancing tabrakan dengan tanker dengan ukuran 336-ton dan terbalik di pantai Korea Selatan.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "MODEL GENERATION - WITHOUT PROMPT ENGINEERING:\n",
      "penjaga pantai berupaya menyelamatkan korban, tujuh orang dilarikan ke rumah sakit penjara pantai korea selatan mengatakan dua orang masih hilang, dan upaya pencarian masih dilakukan.\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Example 2\n",
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "Vincent Tan sering terlihat memakai kaca mata gelap dan sarung tangan. Tan juga menegaskan bahwa dirinya 'bukan orang yang jahat'. \"Sebaik apa pun Anda, pasti akan ada beberapa orang yang tidak mendukung Anda,\" kata Tan dalam wawancara khusus dengan BBC Sport. Tan diserang mulai dari caranya menjalankan klub hingga kebiasaannya memakai kacamata gelap dan sarung tangan saat menonton pertandingan Cardiff, yang membuat beberapa pendukung Cardiff menyebut Tan tidak ubahnya tokoh antagonis di film-film James Bond. Dalam wawancara dengan BBC, Tan menjawab serangan tersebut. \"Saya memakai kacamata karena silau. Saya memakai sarung tangan karena cuaca sangat dingin (bila dibandingkan dengan cuaca di Malaysia). Jujur saja komentar soal kacamata dan sarung tangan ini sudah sangat berlebihan,\" kata Tan. \"Media di Inggris juga tidak adil ... mungkin karena kami juga tidak memberi penjelasan. Pada saatnya nanti saya akan jelaskan semuanya. Media di Inggris kadang sedikit rasis,\" kata Tan. Tan membeli Cardiff pada 2010 dan di bawah kepemimpinannya Cardiff berhasil masuk ke Liga Primer. Namun ia juga dikecam karena mengubah warna klub -dari biru ke merah- dan memecat manajer yang populer di kalangan suporter.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "Pemilik klub Cardiff City asal Malaysia, Vincent Tan, menegaskan bahwa ia tidak layak disebut sebagai musuh besar para penggemar klub.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "MODEL GENERATION - WITHOUT PROMPT ENGINEERING:\n",
      "vincent tan sering terlihat memakai kaca mata gelap dan sarung tangan saat menonton pertandingan cardiff, yang membuat beberapa pendukung cardiff menyebut tan tidak ubahnya tokoh antagonis di film - film james bond.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, index in enumerate(example_indices):\n",
    "    dialogue = dataset['test'][index]['text']\n",
    "    summary = dataset['test'][index]['summary']\n",
    "    \n",
    "    inputs = tokenizer(dialogue, return_tensors='pt')\n",
    "    outputs = tokenizer.decode(\n",
    "        model.generate(\n",
    "            inputs[\"input_ids\"], \n",
    "            max_new_tokens=200,\n",
    "            )[0],\n",
    "        skip_special_tokens=True)\n",
    "    \n",
    "    print(dash_line)\n",
    "    print('Example', i+1)\n",
    "    print(dash_line)\n",
    "    print(f'INPUT PROMPT:\\n{dialogue}')\n",
    "    print(dash_line)\n",
    "    print(f'BASELINE HUMAN SUMMARY:\\n{summary}')\n",
    "    print(dash_line)\n",
    "    print(f'MODEL GENERATION - WITHOUT PROMPT ENGINEERING:\\n{outputs}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab177e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "Example 1\n",
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "\n",
      "    Summarize the following conversation\n",
      "    Penjaga pantai berupaya untuk menyelamatkan korban, tujuh orang dilarikan ke rumah sakit Penjara pantai Korea Selatan mengatakan dua orang masih hilang, dan upaya pencarian masih dilakukan. Kapal memancing sewaan, Seonchang-1, membawa 20 penumpang dan dua kru dalam sebuah tur memancing saat tabrakan terjadi. Cuplikan gambar dari lokasi kejadian menunjukkan para penyelam sedang mencari korban perahu yang terbalik. Helikopter Angkatan Laut dan puluhan kapal lain ikut dalam pencarian di Incheon, yang terletak dekat pulau Yeongheung. Tujuh orang dibawa ke rumah sakit untuk mendapatkan perawatan. Kapten kapal memancing berukuran 10 ton itu masih hilang, menurut salah satu laporan AFP. Tidak ada laporan korban luka dari kru kapan tanker dengan ukuran 336-ton tersebut. Kantor berita Korea Selatan Yonhap mengatakan tabrakan terjadi sembilan menit setelah kapal berangkat dari pantai, kemungkinan ketika dua kapal itu bertemu di bawah sebuah jembatan. \"Tidak ada masalah dengan kondisi cuaca, laporan pelayaran atau persiapan lainnya (pra-keberangkatan),\" kata seorang petugas penjaga pantai kepada wartawan. \"Kami menginvestigasi bagaimana kecelakaan terjadi.\" Temperatur air yang dingin mungkin juga menyebabkan korban jiwa, jelas petugas pantai. Kecelakaan ini merupakan yang terburuk di Korea Selatan sejak insiden tur memancing di dekat pulau Jeju yang menyebabkan 15 orang tewas pada 2015 lalu. Setahun sebelumnya, sebuah kapal feri penumpang terbalik dan menyebabkan 300 orang meninggal, sebagian besar dari mereka anak-anak sekolah yang tengah piknik.\n",
      "    Summary:\n",
      "    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "Sedikitnya 13 orang tewas setelah sebuah kapal memancing tabrakan dengan tanker dengan ukuran 336-ton dan terbalik di pantai Korea Selatan.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "MODEL GENERATION - NO PROMPT ENGINEERING:\n",
      "petugas pantai berupaya menyelamatkan korban, tujuh orang dilarikan ke rumah sakit penjara pantai korea selatan mengatakan dua orang masih hilang, dan upaya pencarian masih dilakukan.\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Example 2\n",
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "\n",
      "    Summarize the following conversation\n",
      "    Vincent Tan sering terlihat memakai kaca mata gelap dan sarung tangan. Tan juga menegaskan bahwa dirinya 'bukan orang yang jahat'. \"Sebaik apa pun Anda, pasti akan ada beberapa orang yang tidak mendukung Anda,\" kata Tan dalam wawancara khusus dengan BBC Sport. Tan diserang mulai dari caranya menjalankan klub hingga kebiasaannya memakai kacamata gelap dan sarung tangan saat menonton pertandingan Cardiff, yang membuat beberapa pendukung Cardiff menyebut Tan tidak ubahnya tokoh antagonis di film-film James Bond. Dalam wawancara dengan BBC, Tan menjawab serangan tersebut. \"Saya memakai kacamata karena silau. Saya memakai sarung tangan karena cuaca sangat dingin (bila dibandingkan dengan cuaca di Malaysia). Jujur saja komentar soal kacamata dan sarung tangan ini sudah sangat berlebihan,\" kata Tan. \"Media di Inggris juga tidak adil ... mungkin karena kami juga tidak memberi penjelasan. Pada saatnya nanti saya akan jelaskan semuanya. Media di Inggris kadang sedikit rasis,\" kata Tan. Tan membeli Cardiff pada 2010 dan di bawah kepemimpinannya Cardiff berhasil masuk ke Liga Primer. Namun ia juga dikecam karena mengubah warna klub -dari biru ke merah- dan memecat manajer yang populer di kalangan suporter.\n",
      "    Summary:\n",
      "    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "Pemilik klub Cardiff City asal Malaysia, Vincent Tan, menegaskan bahwa ia tidak layak disebut sebagai musuh besar para penggemar klub.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "MODEL GENERATION - NO PROMPT ENGINEERING:\n",
      "waterarize joe tan sering terlihat memakai kaca mata gelap dan sarung tangan saat menonton pertandingan cardiff, yang membuat beberapa pendukung cardiff menyebut tan tidak ubahnya tokoh antagonis di film james bond.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, index in enumerate(example_indices):\n",
    "    dialogue = dataset['test'][index]['text']\n",
    "    summary = dataset['test'][index]['summary']\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Summarize the following conversation\n",
    "    {dialogue}\n",
    "    Summary:\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    inputs = tokenizer(prompt, return_tensors='pt')\n",
    "    outputs = tokenizer.decode(\n",
    "        model.generate(\n",
    "            inputs[\"input_ids\"],\n",
    "            max_new_tokens=100,\n",
    "        )[0],\n",
    "        skip_special_tokens=True)\n",
    "    \n",
    "    print(dash_line)\n",
    "    print('Example', i+1)\n",
    "    print(dash_line)\n",
    "    print(f'INPUT PROMPT:\\n{prompt}')\n",
    "    print(dash_line)\n",
    "    print(f'BASELINE HUMAN SUMMARY:\\n{summary}')\n",
    "    print(dash_line)\n",
    "    print(f'MODEL GENERATION - NO PROMPT ENGINEERING:\\n{outputs}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1acb2233",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "Example 1\n",
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "\n",
      "    Summarize the following conversation\n",
      "    Penjaga pantai berupaya untuk menyelamatkan korban, tujuh orang dilarikan ke rumah sakit Penjara pantai Korea Selatan mengatakan dua orang masih hilang, dan upaya pencarian masih dilakukan. Kapal memancing sewaan, Seonchang-1, membawa 20 penumpang dan dua kru dalam sebuah tur memancing saat tabrakan terjadi. Cuplikan gambar dari lokasi kejadian menunjukkan para penyelam sedang mencari korban perahu yang terbalik. Helikopter Angkatan Laut dan puluhan kapal lain ikut dalam pencarian di Incheon, yang terletak dekat pulau Yeongheung. Tujuh orang dibawa ke rumah sakit untuk mendapatkan perawatan. Kapten kapal memancing berukuran 10 ton itu masih hilang, menurut salah satu laporan AFP. Tidak ada laporan korban luka dari kru kapan tanker dengan ukuran 336-ton tersebut. Kantor berita Korea Selatan Yonhap mengatakan tabrakan terjadi sembilan menit setelah kapal berangkat dari pantai, kemungkinan ketika dua kapal itu bertemu di bawah sebuah jembatan. \"Tidak ada masalah dengan kondisi cuaca, laporan pelayaran atau persiapan lainnya (pra-keberangkatan),\" kata seorang petugas penjaga pantai kepada wartawan. \"Kami menginvestigasi bagaimana kecelakaan terjadi.\" Temperatur air yang dingin mungkin juga menyebabkan korban jiwa, jelas petugas pantai. Kecelakaan ini merupakan yang terburuk di Korea Selatan sejak insiden tur memancing di dekat pulau Jeju yang menyebabkan 15 orang tewas pada 2015 lalu. Setahun sebelumnya, sebuah kapal feri penumpang terbalik dan menyebabkan 300 orang meninggal, sebagian besar dari mereka anak-anak sekolah yang tengah piknik.\n",
      "    \n",
      "    What was going on?\n",
      "    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "Sedikitnya 13 orang tewas setelah sebuah kapal memancing tabrakan dengan tanker dengan ukuran 336-ton dan terbalik di pantai Korea Selatan.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "MODEL GENERATION - ZERO SHOT:\n",
      "petugas pantai berupaya menyelamatkan korban, tujuh orang dilarikan ke rumah sakit penjara pantai korea selatan mengatakan dua orang masih hilang, dan upaya pencarian masih dilakukan.\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Example 2\n",
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "\n",
      "    Summarize the following conversation\n",
      "    Vincent Tan sering terlihat memakai kaca mata gelap dan sarung tangan. Tan juga menegaskan bahwa dirinya 'bukan orang yang jahat'. \"Sebaik apa pun Anda, pasti akan ada beberapa orang yang tidak mendukung Anda,\" kata Tan dalam wawancara khusus dengan BBC Sport. Tan diserang mulai dari caranya menjalankan klub hingga kebiasaannya memakai kacamata gelap dan sarung tangan saat menonton pertandingan Cardiff, yang membuat beberapa pendukung Cardiff menyebut Tan tidak ubahnya tokoh antagonis di film-film James Bond. Dalam wawancara dengan BBC, Tan menjawab serangan tersebut. \"Saya memakai kacamata karena silau. Saya memakai sarung tangan karena cuaca sangat dingin (bila dibandingkan dengan cuaca di Malaysia). Jujur saja komentar soal kacamata dan sarung tangan ini sudah sangat berlebihan,\" kata Tan. \"Media di Inggris juga tidak adil ... mungkin karena kami juga tidak memberi penjelasan. Pada saatnya nanti saya akan jelaskan semuanya. Media di Inggris kadang sedikit rasis,\" kata Tan. Tan membeli Cardiff pada 2010 dan di bawah kepemimpinannya Cardiff berhasil masuk ke Liga Primer. Namun ia juga dikecam karena mengubah warna klub -dari biru ke merah- dan memecat manajer yang populer di kalangan suporter.\n",
      "    \n",
      "    What was going on?\n",
      "    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "Pemilik klub Cardiff City asal Malaysia, Vincent Tan, menegaskan bahwa ia tidak layak disebut sebagai musuh besar para penggemar klub.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "MODEL GENERATION - ZERO SHOT:\n",
      "waterarize joe tan sering terlihat memakai kaca mata gelap dan sarung tangan saat menonton pertandingan cardiff, yang membuat beberapa pendukung cardiff menyebut tan tidak ubahnya tokoh antagonis di film james bond.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, index in enumerate(example_indices):\n",
    "    dialogue = dataset['test'][index]['text']\n",
    "    summary = dataset['test'][index]['summary']\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Summarize the following conversation\n",
    "    {dialogue}\n",
    "    \n",
    "    What was going on?\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    inputs = tokenizer(prompt, return_tensors='pt')\n",
    "    outputs = tokenizer.decode(\n",
    "        model.generate(\n",
    "            inputs[\"input_ids\"],\n",
    "            max_new_tokens=100,\n",
    "        )[0],\n",
    "        skip_special_tokens=True)\n",
    "    \n",
    "    print(dash_line)\n",
    "    print('Example', i+1)\n",
    "    print(dash_line)\n",
    "    print(f'INPUT PROMPT:\\n{prompt}')\n",
    "    print(dash_line)\n",
    "    print(f'BASELINE HUMAN SUMMARY:\\n{summary}')\n",
    "    print(dash_line)\n",
    "    print(f'MODEL GENERATION - ZERO SHOT:\\n{outputs}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7d51d7",
   "metadata": {},
   "source": [
    "One-Shot Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "289447de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prompt(example_indices_full, example_index_to_summarize):\n",
    "    prompt =''\n",
    "    for index in example_indices_full:\n",
    "        dialogue = dataset['test'][index]['text']\n",
    "        summary = dataset['test'][index]['summary']\n",
    "        \n",
    "        prompt +=f\"\"\"\n",
    "Dialogue:\n",
    "{dialogue}\n",
    "What was going on?\n",
    "{summary}\n",
    "\"\"\"\n",
    "    dialogue = dataset['test'][example_index_to_summarize]['text']\n",
    "    \n",
    "    prompt +=f\"\"\"\n",
    "Dialogue:\n",
    "{dialogue}\n",
    "What was going on?\n",
    "\"\"\"\n",
    "    return prompt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c61e2ed9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dialogue:\n",
      "Penjaga pantai berupaya untuk menyelamatkan korban, tujuh orang dilarikan ke rumah sakit Penjara pantai Korea Selatan mengatakan dua orang masih hilang, dan upaya pencarian masih dilakukan. Kapal memancing sewaan, Seonchang-1, membawa 20 penumpang dan dua kru dalam sebuah tur memancing saat tabrakan terjadi. Cuplikan gambar dari lokasi kejadian menunjukkan para penyelam sedang mencari korban perahu yang terbalik. Helikopter Angkatan Laut dan puluhan kapal lain ikut dalam pencarian di Incheon, yang terletak dekat pulau Yeongheung. Tujuh orang dibawa ke rumah sakit untuk mendapatkan perawatan. Kapten kapal memancing berukuran 10 ton itu masih hilang, menurut salah satu laporan AFP. Tidak ada laporan korban luka dari kru kapan tanker dengan ukuran 336-ton tersebut. Kantor berita Korea Selatan Yonhap mengatakan tabrakan terjadi sembilan menit setelah kapal berangkat dari pantai, kemungkinan ketika dua kapal itu bertemu di bawah sebuah jembatan. \"Tidak ada masalah dengan kondisi cuaca, laporan pelayaran atau persiapan lainnya (pra-keberangkatan),\" kata seorang petugas penjaga pantai kepada wartawan. \"Kami menginvestigasi bagaimana kecelakaan terjadi.\" Temperatur air yang dingin mungkin juga menyebabkan korban jiwa, jelas petugas pantai. Kecelakaan ini merupakan yang terburuk di Korea Selatan sejak insiden tur memancing di dekat pulau Jeju yang menyebabkan 15 orang tewas pada 2015 lalu. Setahun sebelumnya, sebuah kapal feri penumpang terbalik dan menyebabkan 300 orang meninggal, sebagian besar dari mereka anak-anak sekolah yang tengah piknik.\n",
      "What was going on?\n",
      "Sedikitnya 13 orang tewas setelah sebuah kapal memancing tabrakan dengan tanker dengan ukuran 336-ton dan terbalik di pantai Korea Selatan.\n",
      "\n",
      "Dialogue:\n",
      "Vincent Tan sering terlihat memakai kaca mata gelap dan sarung tangan. Tan juga menegaskan bahwa dirinya 'bukan orang yang jahat'. \"Sebaik apa pun Anda, pasti akan ada beberapa orang yang tidak mendukung Anda,\" kata Tan dalam wawancara khusus dengan BBC Sport. Tan diserang mulai dari caranya menjalankan klub hingga kebiasaannya memakai kacamata gelap dan sarung tangan saat menonton pertandingan Cardiff, yang membuat beberapa pendukung Cardiff menyebut Tan tidak ubahnya tokoh antagonis di film-film James Bond. Dalam wawancara dengan BBC, Tan menjawab serangan tersebut. \"Saya memakai kacamata karena silau. Saya memakai sarung tangan karena cuaca sangat dingin (bila dibandingkan dengan cuaca di Malaysia). Jujur saja komentar soal kacamata dan sarung tangan ini sudah sangat berlebihan,\" kata Tan. \"Media di Inggris juga tidak adil ... mungkin karena kami juga tidak memberi penjelasan. Pada saatnya nanti saya akan jelaskan semuanya. Media di Inggris kadang sedikit rasis,\" kata Tan. Tan membeli Cardiff pada 2010 dan di bawah kepemimpinannya Cardiff berhasil masuk ke Liga Primer. Namun ia juga dikecam karena mengubah warna klub -dari biru ke merah- dan memecat manajer yang populer di kalangan suporter.\n",
      "What was going on?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_indices_full = [40]\n",
    "example_index_to_summarize = 200\n",
    "\n",
    "one_shot_prompt = make_prompt(example_indices_full, example_index_to_summarize)\n",
    "\n",
    "print(one_shot_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "18228bd8",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (525) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 525].  Tensor sizes: [1, 512]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m summary \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m][example_index_to_summarize][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      3\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(one_shot_prompt, return_tensors \u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m outputs \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(\n\u001b[1;32m----> 5\u001b[0m     model\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[0;32m      6\u001b[0m         inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m      7\u001b[0m         max_new_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m,\n\u001b[0;32m      8\u001b[0m             )[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m      9\u001b[0m     skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     10\u001b[0m )\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(dash_line)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mINPUT PROMPT:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mone_shot_prompt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\generation\\utils.py:1268\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, **kwargs)\u001b[0m\n\u001b[0;32m   1260\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m   1261\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA decoder-only architecture is being used, but right-padding was detected! For correct \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1262\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration results, please set `padding_side=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m` when initializing the tokenizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1263\u001b[0m         )\n\u001b[0;32m   1265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m model_kwargs:\n\u001b[0;32m   1266\u001b[0m     \u001b[38;5;66;03m# if model is encoder decoder encoder_outputs are created\u001b[39;00m\n\u001b[0;32m   1267\u001b[0m     \u001b[38;5;66;03m# and added to `model_kwargs`\u001b[39;00m\n\u001b[1;32m-> 1268\u001b[0m     model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_encoder_decoder_kwargs_for_generation(\n\u001b[0;32m   1269\u001b[0m         inputs_tensor, model_kwargs, model_input_name\n\u001b[0;32m   1270\u001b[0m     )\n\u001b[0;32m   1272\u001b[0m \u001b[38;5;66;03m# 5. Prepare `input_ids` which will be used for auto-regressive generation\u001b[39;00m\n\u001b[0;32m   1273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\generation\\utils.py:634\u001b[0m, in \u001b[0;36mGenerationMixin._prepare_encoder_decoder_kwargs_for_generation\u001b[1;34m(self, inputs_tensor, model_kwargs, model_input_name)\u001b[0m\n\u001b[0;32m    632\u001b[0m encoder_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    633\u001b[0m encoder_kwargs[model_input_name] \u001b[38;5;241m=\u001b[39m inputs_tensor\n\u001b[1;32m--> 634\u001b[0m model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m]: ModelOutput \u001b[38;5;241m=\u001b[39m encoder(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mencoder_kwargs)\n\u001b[0;32m    636\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model_kwargs\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:986\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    984\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    985\u001b[0m     buffered_token_type_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings\u001b[38;5;241m.\u001b[39mtoken_type_ids[:, :seq_length]\n\u001b[1;32m--> 986\u001b[0m     buffered_token_type_ids_expanded \u001b[38;5;241m=\u001b[39m buffered_token_type_ids\u001b[38;5;241m.\u001b[39mexpand(batch_size, seq_length)\n\u001b[0;32m    987\u001b[0m     token_type_ids \u001b[38;5;241m=\u001b[39m buffered_token_type_ids_expanded\n\u001b[0;32m    988\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The expanded size of the tensor (525) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 525].  Tensor sizes: [1, 512]"
     ]
    }
   ],
   "source": [
    "summary = dataset['test'][example_index_to_summarize]['text']\n",
    "\n",
    "inputs = tokenizer(one_shot_prompt, return_tensors ='pt')\n",
    "outputs = tokenizer.decode(\n",
    "    model.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        max_new_tokens = 100,\n",
    "            )[0],\n",
    "    skip_special_tokens=True\n",
    ")\n",
    "\n",
    "print(dash_line)\n",
    "print(f'INPUT PROMPT:\\n{one_shot_prompt}')\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{summary}')\n",
    "print(dash_line)\n",
    "print(f'MODEL GENERATION - ONE SHOTS:\\n{outputs}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0ffb28",
   "metadata": {},
   "source": [
    "Few shot inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8c7652ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dialogue:\n",
      "Penjaga pantai berupaya untuk menyelamatkan korban, tujuh orang dilarikan ke rumah sakit Penjara pantai Korea Selatan mengatakan dua orang masih hilang, dan upaya pencarian masih dilakukan. Kapal memancing sewaan, Seonchang-1, membawa 20 penumpang dan dua kru dalam sebuah tur memancing saat tabrakan terjadi. Cuplikan gambar dari lokasi kejadian menunjukkan para penyelam sedang mencari korban perahu yang terbalik. Helikopter Angkatan Laut dan puluhan kapal lain ikut dalam pencarian di Incheon, yang terletak dekat pulau Yeongheung. Tujuh orang dibawa ke rumah sakit untuk mendapatkan perawatan. Kapten kapal memancing berukuran 10 ton itu masih hilang, menurut salah satu laporan AFP. Tidak ada laporan korban luka dari kru kapan tanker dengan ukuran 336-ton tersebut. Kantor berita Korea Selatan Yonhap mengatakan tabrakan terjadi sembilan menit setelah kapal berangkat dari pantai, kemungkinan ketika dua kapal itu bertemu di bawah sebuah jembatan. \"Tidak ada masalah dengan kondisi cuaca, laporan pelayaran atau persiapan lainnya (pra-keberangkatan),\" kata seorang petugas penjaga pantai kepada wartawan. \"Kami menginvestigasi bagaimana kecelakaan terjadi.\" Temperatur air yang dingin mungkin juga menyebabkan korban jiwa, jelas petugas pantai. Kecelakaan ini merupakan yang terburuk di Korea Selatan sejak insiden tur memancing di dekat pulau Jeju yang menyebabkan 15 orang tewas pada 2015 lalu. Setahun sebelumnya, sebuah kapal feri penumpang terbalik dan menyebabkan 300 orang meninggal, sebagian besar dari mereka anak-anak sekolah yang tengah piknik.\n",
      "What was going on?\n",
      "Sedikitnya 13 orang tewas setelah sebuah kapal memancing tabrakan dengan tanker dengan ukuran 336-ton dan terbalik di pantai Korea Selatan.\n",
      "\n",
      "Dialogue:\n",
      "Toyota mengatakan keuntungan bersih kemungkinan dapat mencapai 2 triliun yen. Perusahaan tersebut juga meningkatkan perkiraan penjualan di pasar utamanya, Amerika Utara, yang menunjukkan kinerja kuat. Toyota mengatakan keuntungan bersih kemungkinan dapat mencapai 2 triliun yen atau Rp212 triliun untuk tahun ini sampai bulan Maret 2015. Sebelumnya pembuat kendaraan tersebut memperkirakan keuntungan bersih sebesar 1,78 triliun yen. Presiden Toyota, Nobuyori Kodaira, mengatakan perusahaan tersebut juga meningkatkan perkiraan keuntungan operasi dan pemasukan untuk periode yang sama. \"Kami mengubah perkiraan pemasukan operasi sebesar 200 miliar menjadi 2,5 triliun yen,\" katanya. Dia mengatakan hal ini mewakili kemajuan dalam pemasaran dan pengurangan biaya, disamping perubahan tingkat devisa. Pesaing Toyota, Nissan, hari Selasa (4 November) melaporkan peningkatan keuntungan enam bulan sebesar 25%. Seperti Toyota, Nissan mengatakan kuatnya penjualan di pasar utama Amerika Utara menutupi melemahnya permintaan di sejumlah pasar lain.\n",
      "What was going on?\n",
      "Pembuat kendaraan terbesar Jepang, Toyota, meningkatkan perkiraan keuntungan satu tahunnya sebesar 12,4%, karena melemahnya yen dan usaha penghematan.\n",
      "\n",
      "Dialogue:\n",
      "Jenderal John Kelly (kiri) ditunjuk mengganti Reince Priebus (kanan) yang jadi bulan-bulanan direktur komunikasi baru Trump, Anthony Scaramucci. Pengumuman yang dibuat di Twitter pada hari Jumat sore, sekaligus mencopot kepala Staf sebelumnya Reince Priebus, yang jadi sasaran serangan Anthony Scaramucci, direktur komunikasi baru presiden Trump. Priebus jadi bulan-bulanan sejak dituduh Scaramucci sebagai 'pembocor' informasi kepada media. Dalam wawancara dengan CNN, Reince Priebus mengatakan bahwa dia mengundurkan diri pada hari Kamis setelah berbicara dengan Trump. \"Presiden menginginkan arah yang berbeda,\" katanya kepada Wolf Blitzer, dari CNN, dan menambahkan bahwa menurutnya pemilihan John Kelly merupakan 'keputusan yang brilian.' Anthony Scaramucci, yang ditunjuk sebagai direktur komunikasi sepekan lalu, telah menuduh Priebus sebagai 'pembocor.' Dia juga menelepon seorang wartawan untuk melontarkan kata-kata kasar yang tidak senonoh terhadap Priebus, yang disebutnya sebagai 'penderita skizofrenia yang paranoid.' Reince Preibus dan Anthony Scaramucci, dalam foto yang menjadi bahan telaah para ahli bahasa tubuh, tentang perseteruan kedua orang dekat Donald Trump ini. Dalam serangkaian cuitan pada Jumat sesaat sebelum pukul 17:00 (Sabtu 04:00 WIB) Trump memuji mantan jenderal marinir ini sebagai 'orang Amerika yang hebat' dan 'pemimpin yang hebat.' \"John telah melakukan tugas secara spektakuler di dinas keamanan dalam negeri, dia adalah bintang sejati pemerintahan saya,\" kata presiden. Dia akan mulai bekerja pada hari Senin, juru bicara Gedung Putih mengatakan. Jabatan sebagai Menteri Keamanan Dalam Negeri dialihkan kepada wakilnya, Elaine Duke. John Kelly Dalam cuitan ketiga, Trump memuji Kepala Staf yang dicopotnya, seorang pendukung setia yang sebelumnya merupakan ketua Komite Nasional Partai Republik (Republican National Committee, RNC). \"Saya ingin mengucapkan terima kasih kepada Reince Priebus atas pengabdiannya dan dedikasinya kepada negaranya. Kami menyelesaikan banyak hal bersama-sama dan saya bangga kepadanya,\" katanya. Dalam peran sebelumnya sebagai ketua RNC, dia bertindak sebagai jembatan antara Trump yang saat itu masih calon presiden dengan partai yang seringkali tidak nyaman dengan sikap Trump. Dalam setengah tahun pertama ini, pemerintahan Trump sudah didera oleh berbagai pengunduran diri dan pemecatan para pejabat elit, terutama terkait penyelidikan atas keterlibatan Rusia dalam pemilihan presiden yang menguntungkannya. Sebelumnya, penasihat keamanan nasional Michael Flynn dipaksa mundur hanya 23 hari setelah menjabat. Presiden Trump juga telah memecat Direktur FBI James Comey terkait penyelidikan perkara Rusia, Jaksa Agung Sally Yates terkait kebjakan imigrasi, dan jaksa federal Preet Bharara yang tak mau mengangkat telepon dari Trump karena dianggapnya tak wajar. Jaksa Agung sekarang, Jeff Sessions, yang jabatannya belum lagi enam bulan, juga terancam setelah Trump mengecamnya pedas di Twitter. Sekretaris Pers Gedung Putih Sean Spicer mengundurkan diri saat Anthony Scaramucci diangkat mengisi posisi yang ditinggalkan Mike Dubke setelah tiga bulan menjabat.\n",
      "What was going on?\n",
      "Presiden Donald Trump telah menunjuk Jenderal John Kelly, yang saat ini memimpin Departemen Keamanan Dalam Negeri, sebagai kepala staf Gedung Putih yang baru.\n",
      "\n",
      "Dialogue:\n",
      "Vincent Tan sering terlihat memakai kaca mata gelap dan sarung tangan. Tan juga menegaskan bahwa dirinya 'bukan orang yang jahat'. \"Sebaik apa pun Anda, pasti akan ada beberapa orang yang tidak mendukung Anda,\" kata Tan dalam wawancara khusus dengan BBC Sport. Tan diserang mulai dari caranya menjalankan klub hingga kebiasaannya memakai kacamata gelap dan sarung tangan saat menonton pertandingan Cardiff, yang membuat beberapa pendukung Cardiff menyebut Tan tidak ubahnya tokoh antagonis di film-film James Bond. Dalam wawancara dengan BBC, Tan menjawab serangan tersebut. \"Saya memakai kacamata karena silau. Saya memakai sarung tangan karena cuaca sangat dingin (bila dibandingkan dengan cuaca di Malaysia). Jujur saja komentar soal kacamata dan sarung tangan ini sudah sangat berlebihan,\" kata Tan. \"Media di Inggris juga tidak adil ... mungkin karena kami juga tidak memberi penjelasan. Pada saatnya nanti saya akan jelaskan semuanya. Media di Inggris kadang sedikit rasis,\" kata Tan. Tan membeli Cardiff pada 2010 dan di bawah kepemimpinannya Cardiff berhasil masuk ke Liga Primer. Namun ia juga dikecam karena mengubah warna klub -dari biru ke merah- dan memecat manajer yang populer di kalangan suporter.\n",
      "What was going on?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_indices_full = [40, 80, 120]\n",
    "example_index_to_summarize = 200\n",
    "\n",
    "few_shot_prompt = make_prompt(example_indices_full, example_index_to_summarize)\n",
    "\n",
    "print(few_shot_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "faae3f2d",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (1332) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 1332].  Tensor sizes: [1, 512]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m summary \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m][example_index_to_summarize][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      3\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(few_shot_prompt, return_tensors \u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m outputs \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(\n\u001b[1;32m----> 5\u001b[0m     model\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[0;32m      6\u001b[0m         inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m      7\u001b[0m         max_new_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m,\n\u001b[0;32m      8\u001b[0m     )[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m      9\u001b[0m     skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     10\u001b[0m )\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(dash_line)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBASELINE HUMAN SUMMARY:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msummary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\generation\\utils.py:1268\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, **kwargs)\u001b[0m\n\u001b[0;32m   1260\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m   1261\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA decoder-only architecture is being used, but right-padding was detected! For correct \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1262\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration results, please set `padding_side=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m` when initializing the tokenizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1263\u001b[0m         )\n\u001b[0;32m   1265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m model_kwargs:\n\u001b[0;32m   1266\u001b[0m     \u001b[38;5;66;03m# if model is encoder decoder encoder_outputs are created\u001b[39;00m\n\u001b[0;32m   1267\u001b[0m     \u001b[38;5;66;03m# and added to `model_kwargs`\u001b[39;00m\n\u001b[1;32m-> 1268\u001b[0m     model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_encoder_decoder_kwargs_for_generation(\n\u001b[0;32m   1269\u001b[0m         inputs_tensor, model_kwargs, model_input_name\n\u001b[0;32m   1270\u001b[0m     )\n\u001b[0;32m   1272\u001b[0m \u001b[38;5;66;03m# 5. Prepare `input_ids` which will be used for auto-regressive generation\u001b[39;00m\n\u001b[0;32m   1273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\generation\\utils.py:634\u001b[0m, in \u001b[0;36mGenerationMixin._prepare_encoder_decoder_kwargs_for_generation\u001b[1;34m(self, inputs_tensor, model_kwargs, model_input_name)\u001b[0m\n\u001b[0;32m    632\u001b[0m encoder_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    633\u001b[0m encoder_kwargs[model_input_name] \u001b[38;5;241m=\u001b[39m inputs_tensor\n\u001b[1;32m--> 634\u001b[0m model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m]: ModelOutput \u001b[38;5;241m=\u001b[39m encoder(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mencoder_kwargs)\n\u001b[0;32m    636\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model_kwargs\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:986\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    984\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    985\u001b[0m     buffered_token_type_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings\u001b[38;5;241m.\u001b[39mtoken_type_ids[:, :seq_length]\n\u001b[1;32m--> 986\u001b[0m     buffered_token_type_ids_expanded \u001b[38;5;241m=\u001b[39m buffered_token_type_ids\u001b[38;5;241m.\u001b[39mexpand(batch_size, seq_length)\n\u001b[0;32m    987\u001b[0m     token_type_ids \u001b[38;5;241m=\u001b[39m buffered_token_type_ids_expanded\n\u001b[0;32m    988\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The expanded size of the tensor (1332) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 1332].  Tensor sizes: [1, 512]"
     ]
    }
   ],
   "source": [
    "summary = dataset['test'][example_index_to_summarize]['text']\n",
    "\n",
    "inputs = tokenizer(few_shot_prompt, return_tensors ='pt')\n",
    "outputs = tokenizer.decode(\n",
    "    model.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        max_new_tokens = 100,\n",
    "    )[0],\n",
    "    skip_special_tokens=True\n",
    ")\n",
    "\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{summary}')\n",
    "print(dash_line)\n",
    "print(f'MODEL GENERATION - FEW SHOTS:\\n{outputs}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0f6704",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
